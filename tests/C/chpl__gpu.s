//
// Generated by LLVM NVPTX Back-End
//

.version 7.5
.target sm_60
.address_size 64

.visible .func _local_deinit_chpl
(
	.param .align 8 .b8 _local_deinit_chpl_param_0[16]
)
;
.visible .func  (.param .b32 func_retval0) _local_dsiMember_chpl
(
	.param .b64 _local_dsiMember_chpl_param_0,
	.param .b64 _local_dsiMember_chpl_param_1
)
;
.visible .func  (.param .b32 func_retval0) dsiMember_chpl
(
	.param .b64 dsiMember_chpl_param_0,
	.param .b64 dsiMember_chpl_param_1
)
;
.func  (.param .b32 func_retval0) _ZL21chpl_gpu_getBlockIdxXv
()
;
.func  (.param .b32 func_retval0) _ZL21chpl_gpu_getBlockDimXv
()
;
.func  (.param .b32 func_retval0) _ZL22chpl_gpu_getThreadIdxXv
()
;
.func  (.param .align 16 .b8 func_retval0[8]) _ZL20chpl_gen_getLocaleIDv
()
;
.func  (.param .b32 func_retval0) _ZL24chpl_rt_nodeFromLocaleID15chpl_localeID_t
(
	.param .align 16 .b8 _ZL24chpl_rt_nodeFromLocaleID15chpl_localeID_t_param_0[8]
)
;
.func  (.param .b32 func_retval0) _ZL26chpl_rt_sublocFromLocaleID15chpl_localeID_t
(
	.param .align 16 .b8 _ZL26chpl_rt_sublocFromLocaleID15chpl_localeID_t_param_0[8]
)
;
.func  (.param .b32 func_retval0) _ZL15get_chpl_nodeIDv
()
;
.func  (.param .b32 func_retval0) _ZL28chpl_task_getRequestedSublocv
()
;
.visible .global .align 4 .u32 chpl__cid_RootClass_chpl = 1;
.visible .global .align 4 .u32 chpl__cid_chpl___EndCountBase = 2;
.visible .global .align 4 .u32 chpl__cid_chpl___EndCount_AtomicT_int64_t_int64_t = 3;
.visible .global .align 4 .u32 chpl__cid_chpl_ModuleDeinit = 4;
.visible .global .align 4 .u32 chpl__cid_BaseDist_chpl = 5;
.visible .global .align 4 .u32 chpl__cid_BaseDom_chpl = 7;
.visible .global .align 4 .u32 chpl__cid_BaseRectangularDom_1_int64_t_one_chpl = 8;
.visible .global .align 4 .u32 chpl__cid_BaseRectangularDom_2_int64_t_one_chpl = 10;
.visible .global .align 4 .u32 chpl__cid_BaseArr_chpl = 12;
.visible .global .align 4 .u32 chpl__cid_BaseArrOverRectangularDom_1_int64_t_one_chpl = 13;
.visible .global .align 4 .u32 chpl__cid_BaseArrOverRectangularDom_2_int64_t_one_chpl = 22;
.visible .global .align 4 .u32 chpl__cid_BaseRectangularArr_1_int64_t_one_AbstractLocaleModel_chpl = 14;
.visible .global .align 4 .u32 chpl__cid_BaseRectangularArr_1_int64_t_one_int64_t_chpl = 16;
.visible .global .align 4 .u32 chpl__cid_BaseRectangularArr_1_int64_t_one_locale_chpl = 18;
.visible .global .align 4 .u32 chpl__cid_BaseRectangularArr_1_int64_t_one_uint64_t_chpl = 20;
.visible .global .align 4 .u32 chpl__cid_BaseRectangularArr_2_int64_t_one__real64_chpl = 23;
.visible .global .align 4 .u32 chpl__cid_BaseLocale_chpl = 25;
.visible .global .align 4 .u32 chpl__cid_DummyLocale_chpl = 26;
.visible .global .align 4 .u32 chpl__cid_AbstractLocaleModel_chpl = 27;
.visible .global .align 4 .u32 chpl__cid_AbstractRootLocale_chpl = 30;
.visible .global .align 4 .u32 chpl__cid__ic_chpl_direct_counted_range_iter_chpl = 32;
.visible .global .align 4 .u32 chpl__cid__ic_chpl_direct_counted_range_iter_helper_chpl = 33;
.visible .global .align 4 .u32 chpl__cid__ic_chpl_direct_param_stride_range_iter_chpl = 34;
.visible .global .align 4 .u32 chpl__cid__ic_these_range_int64_t_both_one_chpl = 35;
.visible .global .align 4 .u32 chpl__cid_DefaultDist_chpl = 6;
.visible .global .align 4 .u32 chpl__cid_DefaultRectangularDom_1_int64_t_one_chpl = 9;
.visible .global .align 4 .u32 chpl__cid_DefaultRectangularDom_2_int64_t_one_chpl = 11;
.visible .global .align 4 .u32 chpl__cid_DefaultRectangularArr_1_int64_t_one_AbstractLocaleModel_int64_t_chpl = 15;
.visible .global .align 4 .u32 chpl__cid_DefaultRectangularArr_1_int64_t_one_int64_t_int64_t_chpl = 17;
.visible .global .align 4 .u32 chpl__cid_DefaultRectangularArr_1_int64_t_one_locale_int64_t_chpl = 19;
.visible .global .align 4 .u32 chpl__cid_DefaultRectangularArr_1_int64_t_one_uint64_t_int64_t_chpl = 21;
.visible .global .align 4 .u32 chpl__cid_DefaultRectangularArr_2_int64_t_one__real64_int64_t_chpl = 24;
.visible .global .align 4 .u32 chpl__cid_GPULocale_chpl = 28;
.visible .global .align 4 .u32 chpl__cid_LocaleModel_0_chpl = 29;
.visible .global .align 4 .u32 chpl__cid_RootLocale_chpl = 31;
.visible .global .align 4 .u32 chpl__cid_ReferenceCount_chpl = 36;
.visible .global .align 4 .u32 chpl__cid__ic_chpl_bytes__ref_string_chpl = 37;
.visible .global .align 4 .u32 chpl__cid_Error_chpl = 38;
.visible .global .align 4 .u32 chpl__cid_NilThrownError_chpl = 39;
.visible .global .align 4 .u32 chpl__cid_NilClassError_chpl = 40;
.visible .global .align 4 .u32 chpl__cid_ClassCastError_chpl = 41;
.visible .global .align 4 .u32 chpl__cid_DecodeError_chpl = 42;
.visible .global .align 4 .u32 chpl__cid_IllegalArgumentError_chpl = 43;
.visible .global .align 4 .u32 chpl__cid_CodepointSplitError_chpl = 44;
.visible .global .align 4 .u32 chpl__cid_TaskErrors_chpl = 45;
.visible .global .align 4 .u32 chpl__cid_QioPluginFile_chpl = 66;
.visible .global .align 4 .u32 chpl__cid_QioPluginChannel_chpl = 67;
.visible .global .align 4 .u32 chpl__cid__serializeWrapper_binaryDeserializer_chpl = 68;
.visible .global .align 4 .u32 chpl__cid__serializeWrapper_binarySerializer_chpl = 69;
.visible .global .align 4 .u32 chpl__cid__serializeWrapper_defaultDeserializer_chpl = 70;
.visible .global .align 4 .u32 chpl__cid__serializeWrapper_defaultSerializer_chpl = 71;
.visible .global .align 4 .u32 chpl__cid_SystemError_chpl = 46;
.visible .global .align 4 .u32 chpl__cid_BlockingIoError_chpl = 47;
.visible .global .align 4 .u32 chpl__cid_ChildProcessError_chpl = 48;
.visible .global .align 4 .u32 chpl__cid_ConnectionError_chpl = 49;
.visible .global .align 4 .u32 chpl__cid_BrokenPipeError_chpl = 50;
.visible .global .align 4 .u32 chpl__cid_ConnectionAbortedError_chpl = 51;
.visible .global .align 4 .u32 chpl__cid_ConnectionRefusedError_chpl = 52;
.visible .global .align 4 .u32 chpl__cid_ConnectionResetError_chpl = 53;
.visible .global .align 4 .u32 chpl__cid_FileExistsError_chpl = 54;
.visible .global .align 4 .u32 chpl__cid_FileNotFoundError_chpl = 55;
.visible .global .align 4 .u32 chpl__cid_InterruptedError_chpl = 56;
.visible .global .align 4 .u32 chpl__cid_IsADirectoryError_chpl = 57;
.visible .global .align 4 .u32 chpl__cid_NotADirectoryError_chpl = 58;
.visible .global .align 4 .u32 chpl__cid_PermissionError_chpl = 59;
.visible .global .align 4 .u32 chpl__cid_ProcessLookupError_chpl = 60;
.visible .global .align 4 .u32 chpl__cid_TimeoutError_chpl = 61;
.visible .global .align 4 .u32 chpl__cid_IoError_chpl = 62;
.visible .global .align 4 .u32 chpl__cid_EofError_chpl = 63;
.visible .global .align 4 .u32 chpl__cid_UnexpectedEofError_chpl = 64;
.visible .global .align 4 .u32 chpl__cid_BadFormatError_chpl = 65;
.visible .global .align 4 .u32 chpl__cid_Timezone_chpl = 72;
.visible .global .align 4 .u32 chpl_numGlobalsOnHeap;
.visible .global .align 8 .b8 chpl_globals_registry[8];
.global .align 1 .b8 __unnamed_1[12] = {68, 101, 99, 111, 100, 101, 69, 114, 114, 111, 114, 0};
.visible .global .align 8 .u64 _cstr_literal_4871 = generic(__unnamed_1);
.global .align 1 .b8 __unnamed_2[15] = {78, 105, 108, 84, 104, 114, 111, 119, 110, 69, 114, 114, 111, 114, 0};
.visible .global .align 8 .u64 _cstr_literal_4872 = generic(__unnamed_2);
.global .align 1 .b8 __unnamed_3[40] = {95, 105, 99, 95, 99, 104, 112, 108, 95, 100, 105, 114, 101, 99, 116, 95, 112, 97, 114, 97, 109, 95, 115, 116, 114, 105, 100, 101, 95, 114, 97, 110, 103, 101, 95, 105, 116, 101, 114, 0};
.visible .global .align 8 .u64 _cstr_literal_4873 = generic(__unnamed_3);
.global .align 1 .b8 __unnamed_4[42] = {95, 105, 99, 95, 99, 104, 112, 108, 95, 100, 105, 114, 101, 99, 116, 95, 99, 111, 117, 110, 116, 101, 100, 95, 114, 97, 110, 103, 101, 95, 105, 116, 101, 114, 95, 104, 101, 108, 112, 101, 114, 0};
.visible .global .align 8 .u64 _cstr_literal_4874 = generic(__unnamed_4);
.global .align 1 .b8 __unnamed_5[35] = {95, 105, 99, 95, 99, 104, 112, 108, 95, 100, 105, 114, 101, 99, 116, 95, 99, 111, 117, 110, 116, 101, 100, 95, 114, 97, 110, 103, 101, 95, 105, 116, 101, 114, 0};
.visible .global .align 8 .u64 _cstr_literal_4875 = generic(__unnamed_5);
.global .align 1 .b8 __unnamed_6[34] = {95, 69, 110, 100, 67, 111, 117, 110, 116, 40, 97, 116, 111, 109, 105, 99, 32, 105, 110, 116, 40, 54, 52, 41, 44, 105, 110, 116, 40, 54, 52, 41, 41, 0};
.visible .global .align 8 .u64 _cstr_literal_4876 = generic(__unnamed_6);
.global .align 1 .b8 __unnamed_7[12] = {68, 117, 109, 109, 121, 76, 111, 99, 97, 108, 101, 0};
.visible .global .align 8 .u64 _cstr_literal_4877 = generic(__unnamed_7);
.global .align 1 .b8 __unnamed_8[9] = {69, 111, 102, 69, 114, 114, 111, 114, 0};
.visible .global .align 8 .u64 _cstr_literal_4878 = generic(__unnamed_8);
.global .align 1 .b8 __unnamed_9[19] = {85, 110, 101, 120, 112, 101, 99, 116, 101, 100, 69, 111, 102, 69, 114, 114, 111, 114, 0};
.visible .global .align 8 .u64 _cstr_literal_4879 = generic(__unnamed_9);
.global .align 1 .b8 __unnamed_10[15] = {66, 97, 100, 70, 111, 114, 109, 97, 116, 69, 114, 114, 111, 114, 0};
.visible .global .align 8 .u64 _cstr_literal_4880 = generic(__unnamed_10);
.global .align 1 .b8 __unnamed_11[16] = {66, 108, 111, 99, 107, 105, 110, 103, 73, 111, 69, 114, 114, 111, 114, 0};
.visible .global .align 8 .u64 _cstr_literal_4881 = generic(__unnamed_11);
.global .align 1 .b8 __unnamed_12[18] = {67, 104, 105, 108, 100, 80, 114, 111, 99, 101, 115, 115, 69, 114, 114, 111, 114, 0};
.visible .global .align 8 .u64 _cstr_literal_4882 = generic(__unnamed_12);
.global .align 1 .b8 __unnamed_13[16] = {66, 114, 111, 107, 101, 110, 80, 105, 112, 101, 69, 114, 114, 111, 114, 0};
.visible .global .align 8 .u64 _cstr_literal_4883 = generic(__unnamed_13);
.global .align 1 .b8 __unnamed_14[23] = {67, 111, 110, 110, 101, 99, 116, 105, 111, 110, 65, 98, 111, 114, 116, 101, 100, 69, 114, 114, 111, 114, 0};
.visible .global .align 8 .u64 _cstr_literal_4884 = generic(__unnamed_14);
.global .align 1 .b8 __unnamed_15[23] = {67, 111, 110, 110, 101, 99, 116, 105, 111, 110, 82, 101, 102, 117, 115, 101, 100, 69, 114, 114, 111, 114, 0};
.visible .global .align 8 .u64 _cstr_literal_4885 = generic(__unnamed_15);
.global .align 1 .b8 __unnamed_16[21] = {67, 111, 110, 110, 101, 99, 116, 105, 111, 110, 82, 101, 115, 101, 116, 69, 114, 114, 111, 114, 0};
.visible .global .align 8 .u64 _cstr_literal_4886 = generic(__unnamed_16);
.global .align 1 .b8 __unnamed_17[16] = {70, 105, 108, 101, 69, 120, 105, 115, 116, 115, 69, 114, 114, 111, 114, 0};
.visible .global .align 8 .u64 _cstr_literal_4887 = generic(__unnamed_17);
.global .align 1 .b8 __unnamed_18[18] = {70, 105, 108, 101, 78, 111, 116, 70, 111, 117, 110, 100, 69, 114, 114, 111, 114, 0};
.visible .global .align 8 .u64 _cstr_literal_4888 = generic(__unnamed_18);
.global .align 1 .b8 __unnamed_19[17] = {73, 110, 116, 101, 114, 114, 117, 112, 116, 101, 100, 69, 114, 114, 111, 114, 0};
.visible .global .align 8 .u64 _cstr_literal_4889 = generic(__unnamed_19);
.global .align 1 .b8 __unnamed_20[18] = {73, 115, 65, 68, 105, 114, 101, 99, 116, 111, 114, 121, 69, 114, 114, 111, 114, 0};
.visible .global .align 8 .u64 _cstr_literal_4890 = generic(__unnamed_20);
.global .align 1 .b8 __unnamed_21[19] = {78, 111, 116, 65, 68, 105, 114, 101, 99, 116, 111, 114, 121, 69, 114, 114, 111, 114, 0};
.visible .global .align 8 .u64 _cstr_literal_4891 = generic(__unnamed_21);
.global .align 1 .b8 __unnamed_22[16] = {80, 101, 114, 109, 105, 115, 115, 105, 111, 110, 69, 114, 114, 111, 114, 0};
.visible .global .align 8 .u64 _cstr_literal_4892 = generic(__unnamed_22);
.global .align 1 .b8 __unnamed_23[19] = {80, 114, 111, 99, 101, 115, 115, 76, 111, 111, 107, 117, 112, 69, 114, 114, 111, 114, 0};
.visible .global .align 8 .u64 _cstr_literal_4893 = generic(__unnamed_23);
.global .align 1 .b8 __unnamed_24[13] = {84, 105, 109, 101, 111, 117, 116, 69, 114, 114, 111, 114, 0};
.visible .global .align 8 .u64 _cstr_literal_4894 = generic(__unnamed_24);
.global .align 1 .b8 __unnamed_25[8] = {73, 111, 69, 114, 114, 111, 114, 0};
.visible .global .align 8 .u64 _cstr_literal_4895 = generic(__unnamed_25);
.global .align 1 .b8 __unnamed_26[12] = {83, 121, 115, 116, 101, 109, 69, 114, 114, 111, 114, 0};
.visible .global .align 8 .u64 _cstr_literal_4896 = generic(__unnamed_26);
.global .align 1 .b8 __unnamed_27[21] = {73, 108, 108, 101, 103, 97, 108, 65, 114, 103, 117, 109, 101, 110, 116, 69, 114, 114, 111, 114, 0};
.visible .global .align 8 .u64 _cstr_literal_4897 = generic(__unnamed_27);
.global .align 1 .b8 __unnamed_28[39] = {95, 115, 101, 114, 105, 97, 108, 105, 122, 101, 87, 114, 97, 112, 112, 101, 114, 40, 100, 101, 102, 97, 117, 108, 116, 68, 101, 115, 101, 114, 105, 97, 108, 105, 122, 101, 114, 41, 0};
.visible .global .align 8 .u64 _cstr_literal_4898 = generic(__unnamed_28);
.global .align 1 .b8 __unnamed_29[15] = {82, 101, 102, 101, 114, 101, 110, 99, 101, 67, 111, 117, 110, 116, 0};
.visible .global .align 8 .u64 _cstr_literal_4899 = generic(__unnamed_29);
.global .align 1 .b8 __unnamed_30[37] = {95, 115, 101, 114, 105, 97, 108, 105, 122, 101, 87, 114, 97, 112, 112, 101, 114, 40, 100, 101, 102, 97, 117, 108, 116, 83, 101, 114, 105, 97, 108, 105, 122, 101, 114, 41, 0};
.visible .global .align 8 .u64 _cstr_literal_4900 = generic(__unnamed_30);
.global .align 1 .b8 __unnamed_31[27] = {95, 105, 99, 95, 99, 104, 112, 108, 95, 100, 105, 114, 101, 99, 116, 95, 114, 97, 110, 103, 101, 95, 105, 116, 101, 114, 0};
.visible .global .align 8 .u64 _cstr_literal_4901 = generic(__unnamed_31);
.global .align 1 .b8 __unnamed_32[33] = {95, 105, 99, 95, 116, 104, 101, 115, 101, 95, 114, 97, 110, 103, 101, 95, 105, 110, 116, 54, 52, 95, 116, 95, 98, 111, 116, 104, 95, 111, 110, 101, 0};
.visible .global .align 8 .u64 _cstr_literal_4902 = generic(__unnamed_32);
.global .align 1 .b8 __unnamed_33[27] = {95, 105, 99, 95, 99, 104, 112, 108, 95, 98, 121, 116, 101, 115, 95, 95, 114, 101, 102, 95, 115, 116, 114, 105, 110, 103, 0};
.visible .global .align 8 .u64 _cstr_literal_4903 = generic(__unnamed_33);
.global .align 1 .b8 __unnamed_34[26] = {95, 105, 99, 95, 95, 105, 110, 100, 101, 120, 76, 101, 110, 95, 95, 114, 101, 102, 95, 115, 116, 114, 105, 110, 103, 0};
.visible .global .align 8 .u64 _cstr_literal_4904 = generic(__unnamed_34);
.global .align 1 .b8 __unnamed_35[28] = {95, 105, 99, 95, 95, 99, 112, 73, 110, 100, 101, 120, 76, 101, 110, 95, 95, 114, 101, 102, 95, 115, 116, 114, 105, 110, 103, 0};
.visible .global .align 8 .u64 _cstr_literal_4905 = generic(__unnamed_35);
.global .align 1 .b8 __unnamed_36[27] = {95, 105, 99, 95, 99, 111, 100, 101, 112, 111, 105, 110, 116, 115, 95, 95, 114, 101, 102, 95, 115, 116, 114, 105, 110, 103, 0};
.visible .global .align 8 .u64 _cstr_literal_4906 = generic(__unnamed_36);
.global .align 1 .b8 __unnamed_37[20] = {67, 111, 100, 101, 112, 111, 105, 110, 116, 83, 112, 108, 105, 116, 69, 114, 114, 111, 114, 0};
.visible .global .align 8 .u64 _cstr_literal_4907 = generic(__unnamed_37);
.global .align 1 .b8 __unnamed_38[12] = {68, 101, 102, 97, 117, 108, 116, 68, 105, 115, 116, 0};
.visible .global .align 8 .u64 _cstr_literal_4908 = generic(__unnamed_38);
.global .align 1 .b8 __unnamed_39[22] = {100, 111, 109, 97, 105, 110, 40, 49, 44, 105, 110, 116, 40, 54, 52, 41, 44, 111, 110, 101, 41, 0};
.visible .global .align 8 .u64 _cstr_literal_4909 = generic(__unnamed_39);
.global .align 1 .b8 __unnamed_40[31] = {91, 100, 111, 109, 97, 105, 110, 40, 49, 44, 105, 110, 116, 40, 54, 52, 41, 44, 111, 110, 101, 41, 93, 32, 108, 111, 99, 97, 108, 101, 0};
.visible .global .align 8 .u64 _cstr_literal_4910 = generic(__unnamed_40);
.global .align 1 .b8 __unnamed_41[41] = {66, 97, 115, 101, 65, 114, 114, 79, 118, 101, 114, 82, 101, 99, 116, 97, 110, 103, 117, 108, 97, 114, 68, 111, 109, 40, 49, 44, 105, 110, 116, 40, 54, 52, 41, 44, 111, 110, 101, 41, 0};
.visible .global .align 8 .u64 _cstr_literal_4911 = generic(__unnamed_41);
.global .align 1 .b8 __unnamed_42[18] = {95, 105, 99, 95, 95, 97, 114, 114, 115, 95, 66, 97, 115, 101, 68, 111, 109, 0};
.visible .global .align 8 .u64 _cstr_literal_4912 = generic(__unnamed_42);
.global .align 1 .b8 __unnamed_43[21] = {95, 105, 99, 95, 116, 104, 101, 115, 101, 95, 84, 97, 115, 107, 69, 114, 114, 111, 114, 115, 0};
.visible .global .align 8 .u64 _cstr_literal_4913 = generic(__unnamed_43);
.global .align 1 .b8 __unnamed_44[11] = {84, 97, 115, 107, 69, 114, 114, 111, 114, 115, 0};
.visible .global .align 8 .u64 _cstr_literal_4914 = generic(__unnamed_44);
.global .align 1 .b8 __unnamed_45[38] = {95, 105, 99, 95, 99, 104, 112, 108, 95, 100, 105, 114, 101, 99, 116, 95, 112, 111, 115, 95, 115, 116, 114, 105, 100, 101, 95, 114, 97, 110, 103, 101, 95, 105, 116, 101, 114, 0};
.visible .global .align 8 .u64 _cstr_literal_4915 = generic(__unnamed_45);
.global .align 1 .b8 __unnamed_46[25] = {95, 105, 99, 95, 99, 104, 112, 108, 95, 95, 115, 101, 114, 105, 97, 108, 86, 105, 101, 119, 73, 116, 101, 114, 0};
.visible .global .align 8 .u64 _cstr_literal_4916 = generic(__unnamed_46);
.global .align 1 .b8 __unnamed_47[61] = {95, 105, 99, 95, 116, 104, 101, 115, 101, 95, 68, 101, 102, 97, 117, 108, 116, 82, 101, 99, 116, 97, 110, 103, 117, 108, 97, 114, 65, 114, 114, 95, 49, 95, 105, 110, 116, 54, 52, 95, 116, 95, 111, 110, 101, 95, 108, 111, 99, 97, 108, 101, 95, 105, 110, 116, 54, 52, 95, 116, 0};
.visible .global .align 8 .u64 _cstr_literal_4917 = generic(__unnamed_47);
.global .align 1 .b8 __unnamed_48[73] = {95, 105, 99, 95, 116, 104, 101, 115, 101, 95, 95, 114, 101, 102, 95, 95, 97, 114, 114, 97, 121, 95, 68, 101, 102, 97, 117, 108, 116, 82, 101, 99, 116, 97, 110, 103, 117, 108, 97, 114, 65, 114, 114, 95, 49, 95, 105, 110, 116, 54, 52, 95, 116, 95, 111, 110, 101, 95, 108, 111, 99, 97, 108, 101, 95, 105, 110, 116, 54, 52, 95, 116, 0};
.visible .global .align 8 .u64 _cstr_literal_4918 = generic(__unnamed_48);
.global .align 1 .b8 __unnamed_49[11] = {82, 111, 111, 116, 76, 111, 99, 97, 108, 101, 0};
.visible .global .align 8 .u64 _cstr_literal_4919 = generic(__unnamed_49);
.global .align 1 .b8 __unnamed_50[46] = {95, 105, 99, 95, 116, 104, 101, 115, 101, 95, 68, 101, 102, 97, 117, 108, 116, 82, 101, 99, 116, 97, 110, 103, 117, 108, 97, 114, 68, 111, 109, 95, 49, 95, 105, 110, 116, 54, 52, 95, 116, 95, 111, 110, 101, 0};
.visible .global .align 8 .u64 _cstr_literal_4920 = generic(__unnamed_50);
.global .align 1 .b8 __unnamed_51[59] = {95, 105, 99, 95, 116, 104, 101, 115, 101, 95, 95, 114, 101, 102, 95, 95, 100, 111, 109, 97, 105, 110, 95, 68, 101, 102, 97, 117, 108, 116, 82, 101, 99, 116, 97, 110, 103, 117, 108, 97, 114, 68, 111, 109, 95, 49, 95, 105, 110, 116, 54, 52, 95, 116, 95, 111, 110, 101, 0};
.visible .global .align 8 .u64 _cstr_literal_4921 = generic(__unnamed_51);
.global .align 1 .b8 __unnamed_52[42] = {95, 105, 99, 95, 99, 104, 112, 108, 95, 105, 110, 105, 116, 79, 110, 76, 111, 99, 97, 108, 101, 115, 95, 65, 98, 115, 116, 114, 97, 99, 116, 82, 111, 111, 116, 76, 111, 99, 97, 108, 101, 0};
.visible .global .align 8 .u64 _cstr_literal_4922 = generic(__unnamed_52);
.global .align 1 .b8 __unnamed_53[54] = {91, 100, 111, 109, 97, 105, 110, 40, 49, 44, 105, 110, 116, 40, 54, 52, 41, 44, 111, 110, 101, 41, 93, 32, 117, 110, 109, 97, 110, 97, 103, 101, 100, 32, 65, 98, 115, 116, 114, 97, 99, 116, 76, 111, 99, 97, 108, 101, 77, 111, 100, 101, 108, 0};
.visible .global .align 8 .u64 _cstr_literal_4923 = generic(__unnamed_53);
.global .align 1 .b8 __unnamed_54[10] = {71, 80, 85, 76, 111, 99, 97, 108, 101, 0};
.visible .global .align 8 .u64 _cstr_literal_4924 = generic(__unnamed_54);
.global .align 1 .b8 __unnamed_55[15] = {76, 111, 99, 97, 108, 101, 77, 111, 100, 101, 108, 40, 48, 41, 0};
.visible .global .align 8 .u64 _cstr_literal_4925 = generic(__unnamed_55);
.global .align 1 .b8 __unnamed_56[22] = {100, 111, 109, 97, 105, 110, 40, 50, 44, 105, 110, 116, 40, 54, 52, 41, 44, 111, 110, 101, 41, 0};
.visible .global .align 8 .u64 _cstr_literal_4926 = generic(__unnamed_56);
.global .align 1 .b8 __unnamed_57[33] = {91, 100, 111, 109, 97, 105, 110, 40, 50, 44, 105, 110, 116, 40, 54, 52, 41, 44, 111, 110, 101, 41, 93, 32, 114, 101, 97, 108, 40, 54, 52, 41, 0};
.visible .global .align 8 .u64 _cstr_literal_4927 = generic(__unnamed_57);
.global .align 1 .b8 __unnamed_58[51] = {95, 105, 99, 95, 116, 104, 101, 115, 101, 95, 104, 101, 108, 112, 95, 68, 101, 102, 97, 117, 108, 116, 82, 101, 99, 116, 97, 110, 103, 117, 108, 97, 114, 68, 111, 109, 95, 50, 95, 105, 110, 116, 54, 52, 95, 116, 95, 111, 110, 101, 0};
.visible .global .align 8 .u64 _cstr_literal_4928 = generic(__unnamed_58);
.global .align 1 .b8 __unnamed_59[46] = {95, 105, 99, 95, 116, 104, 101, 115, 101, 95, 68, 101, 102, 97, 117, 108, 116, 82, 101, 99, 116, 97, 110, 103, 117, 108, 97, 114, 68, 111, 109, 95, 50, 95, 105, 110, 116, 54, 52, 95, 116, 95, 111, 110, 101, 0};
.visible .global .align 8 .u64 _cstr_literal_4929 = generic(__unnamed_59);
.global .align 1 .b8 __unnamed_60[59] = {95, 105, 99, 95, 116, 104, 101, 115, 101, 95, 95, 114, 101, 102, 95, 95, 100, 111, 109, 97, 105, 110, 95, 68, 101, 102, 97, 117, 108, 116, 82, 101, 99, 116, 97, 110, 103, 117, 108, 97, 114, 68, 111, 109, 95, 50, 95, 105, 110, 116, 54, 52, 95, 116, 95, 111, 110, 101, 0};
.visible .global .align 8 .u64 _cstr_literal_4930 = generic(__unnamed_60);
.global .align 1 .b8 __unnamed_61[41] = {66, 97, 115, 101, 65, 114, 114, 79, 118, 101, 114, 82, 101, 99, 116, 97, 110, 103, 117, 108, 97, 114, 68, 111, 109, 40, 50, 44, 105, 110, 116, 40, 54, 52, 41, 44, 111, 110, 101, 41, 0};
.visible .global .align 8 .u64 _cstr_literal_4931 = generic(__unnamed_61);
.global .align 1 .b8 __unnamed_62[18] = {99, 104, 112, 108, 95, 77, 111, 100, 117, 108, 101, 68, 101, 105, 110, 105, 116, 0};
.visible .global .align 8 .u64 _cstr_literal_4932 = generic(__unnamed_62);
.global .align 1 .b8 __unnamed_63[36] = {95, 115, 101, 114, 105, 97, 108, 105, 122, 101, 87, 114, 97, 112, 112, 101, 114, 40, 98, 105, 110, 97, 114, 121, 83, 101, 114, 105, 97, 108, 105, 122, 101, 114, 41, 0};
.visible .global .align 8 .u64 _cstr_literal_4933 = generic(__unnamed_63);
.global .align 1 .b8 __unnamed_64[38] = {95, 115, 101, 114, 105, 97, 108, 105, 122, 101, 87, 114, 97, 112, 112, 101, 114, 40, 98, 105, 110, 97, 114, 121, 68, 101, 115, 101, 114, 105, 97, 108, 105, 122, 101, 114, 41, 0};
.visible .global .align 8 .u64 _cstr_literal_4934 = generic(__unnamed_64);
.global .align 1 .b8 __unnamed_65[32] = {91, 100, 111, 109, 97, 105, 110, 40, 49, 44, 105, 110, 116, 40, 54, 52, 41, 44, 111, 110, 101, 41, 93, 32, 105, 110, 116, 40, 54, 52, 41, 0};
.visible .global .align 8 .u64 _cstr_literal_4935 = generic(__unnamed_65);
.global .align 1 .b8 __unnamed_66[35] = {95, 105, 99, 95, 99, 104, 112, 108, 95, 100, 105, 114, 101, 99, 116, 95, 115, 116, 114, 105, 100, 101, 100, 95, 114, 97, 110, 103, 101, 95, 105, 116, 101, 114, 0};
.visible .global .align 8 .u64 _cstr_literal_4936 = generic(__unnamed_66);
.global .align 1 .b8 __unnamed_67[33] = {91, 100, 111, 109, 97, 105, 110, 40, 49, 44, 105, 110, 116, 40, 54, 52, 41, 44, 111, 110, 101, 41, 93, 32, 117, 105, 110, 116, 40, 54, 52, 41, 0};
.visible .global .align 8 .u64 _cstr_literal_4937 = generic(__unnamed_67);
.global .align 1 .b8 __unnamed_68[63] = {95, 105, 99, 95, 116, 104, 101, 115, 101, 95, 68, 101, 102, 97, 117, 108, 116, 82, 101, 99, 116, 97, 110, 103, 117, 108, 97, 114, 65, 114, 114, 95, 49, 95, 105, 110, 116, 54, 52, 95, 116, 95, 111, 110, 101, 95, 117, 105, 110, 116, 54, 52, 95, 116, 95, 105, 110, 116, 54, 52, 95, 116, 0};
.visible .global .align 8 .u64 _cstr_literal_4938 = generic(__unnamed_68);
.global .align 1 .b8 __unnamed_69[75] = {95, 105, 99, 95, 116, 104, 101, 115, 101, 95, 95, 114, 101, 102, 95, 95, 97, 114, 114, 97, 121, 95, 68, 101, 102, 97, 117, 108, 116, 82, 101, 99, 116, 97, 110, 103, 117, 108, 97, 114, 65, 114, 114, 95, 49, 95, 105, 110, 116, 54, 52, 95, 116, 95, 111, 110, 101, 95, 117, 105, 110, 116, 54, 52, 95, 116, 95, 105, 110, 116, 54, 52, 95, 116, 0};
.visible .global .align 8 .u64 _cstr_literal_4939 = generic(__unnamed_69);
.global .align 1 .b8 __unnamed_70[51] = {95, 105, 99, 95, 116, 104, 101, 115, 101, 95, 104, 101, 108, 112, 95, 68, 101, 102, 97, 117, 108, 116, 82, 101, 99, 116, 97, 110, 103, 117, 108, 97, 114, 68, 111, 109, 95, 49, 95, 105, 110, 116, 54, 52, 95, 116, 95, 111, 110, 101, 0};
.visible .global .align 8 .u64 _cstr_literal_4940 = generic(__unnamed_70);
.global .align 1 .b8 __unnamed_71[74] = {95, 105, 99, 95, 116, 104, 101, 115, 101, 95, 68, 101, 102, 97, 117, 108, 116, 82, 101, 99, 116, 97, 110, 103, 117, 108, 97, 114, 65, 114, 114, 95, 49, 95, 105, 110, 116, 54, 52, 95, 116, 95, 111, 110, 101, 95, 65, 98, 115, 116, 114, 97, 99, 116, 76, 111, 99, 97, 108, 101, 77, 111, 100, 101, 108, 95, 105, 110, 116, 54, 52, 95, 116, 0};
.visible .global .align 8 .u64 _cstr_literal_4941 = generic(__unnamed_71);
.global .align 1 .b8 __unnamed_72[86] = {95, 105, 99, 95, 116, 104, 101, 115, 101, 95, 95, 114, 101, 102, 95, 95, 97, 114, 114, 97, 121, 95, 68, 101, 102, 97, 117, 108, 116, 82, 101, 99, 116, 97, 110, 103, 117, 108, 97, 114, 65, 114, 114, 95, 49, 95, 105, 110, 116, 54, 52, 95, 116, 95, 111, 110, 101, 95, 65, 98, 115, 116, 114, 97, 99, 116, 76, 111, 99, 97, 108, 101, 77, 111, 100, 101, 108, 95, 105, 110, 116, 54, 52, 95, 116, 0};
.visible .global .align 8 .u64 _cstr_literal_4942 = generic(__unnamed_72);
.global .align 1 .b8 __unnamed_73[62] = {95, 105, 99, 95, 116, 104, 101, 115, 101, 95, 68, 101, 102, 97, 117, 108, 116, 82, 101, 99, 116, 97, 110, 103, 117, 108, 97, 114, 65, 114, 114, 95, 50, 95, 105, 110, 116, 54, 52, 95, 116, 95, 111, 110, 101, 95, 95, 114, 101, 97, 108, 54, 52, 95, 105, 110, 116, 54, 52, 95, 116, 0};
.visible .global .align 8 .u64 _cstr_literal_4943 = generic(__unnamed_73);
.global .align 1 .b8 __unnamed_74[74] = {95, 105, 99, 95, 116, 104, 101, 115, 101, 95, 95, 114, 101, 102, 95, 95, 97, 114, 114, 97, 121, 95, 68, 101, 102, 97, 117, 108, 116, 82, 101, 99, 116, 97, 110, 103, 117, 108, 97, 114, 65, 114, 114, 95, 50, 95, 105, 110, 116, 54, 52, 95, 116, 95, 111, 110, 101, 95, 95, 114, 101, 97, 108, 54, 52, 95, 105, 110, 116, 54, 52, 95, 116, 0};
.visible .global .align 8 .u64 _cstr_literal_4944 = generic(__unnamed_74);
.global .align 1 .b8 __unnamed_75[31] = {95, 105, 99, 95, 99, 104, 112, 108, 95, 95, 115, 101, 114, 105, 97, 108, 86, 105, 101, 119, 73, 116, 101, 114, 72, 101, 108, 112, 101, 114, 0};
.visible .global .align 8 .u64 _cstr_literal_4945 = generic(__unnamed_75);
.global .align 1 .b8 __unnamed_76[62] = {95, 105, 99, 95, 116, 104, 101, 115, 101, 95, 68, 101, 102, 97, 117, 108, 116, 82, 101, 99, 116, 97, 110, 103, 117, 108, 97, 114, 65, 114, 114, 95, 49, 95, 105, 110, 116, 54, 52, 95, 116, 95, 111, 110, 101, 95, 105, 110, 116, 54, 52, 95, 116, 95, 105, 110, 116, 54, 52, 95, 116, 0};
.visible .global .align 8 .u64 _cstr_literal_4946 = generic(__unnamed_76);
.global .align 1 .b8 __unnamed_77[74] = {95, 105, 99, 95, 116, 104, 101, 115, 101, 95, 95, 114, 101, 102, 95, 95, 97, 114, 114, 97, 121, 95, 68, 101, 102, 97, 117, 108, 116, 82, 101, 99, 116, 97, 110, 103, 117, 108, 97, 114, 65, 114, 114, 95, 49, 95, 105, 110, 116, 54, 52, 95, 116, 95, 111, 110, 101, 95, 105, 110, 116, 54, 52, 95, 116, 95, 105, 110, 116, 54, 52, 95, 116, 0};
.visible .global .align 8 .u64 _cstr_literal_4947 = generic(__unnamed_77);
.global .align 1 .b8 __unnamed_78[14] = {78, 105, 108, 67, 108, 97, 115, 115, 69, 114, 114, 111, 114, 0};
.visible .global .align 8 .u64 _cstr_literal_4948 = generic(__unnamed_78);
.global .align 1 .b8 __unnamed_79[15] = {67, 108, 97, 115, 115, 67, 97, 115, 116, 69, 114, 114, 111, 114, 0};
.visible .global .align 8 .u64 _cstr_literal_4949 = generic(__unnamed_79);
.visible .global .align 8 .u64 chpl_mem_descs[122] = {generic(__unnamed_1), generic(__unnamed_2), generic(__unnamed_3), generic(__unnamed_4), generic(__unnamed_5), generic(__unnamed_6), generic(__unnamed_7), generic(__unnamed_8), generic(__unnamed_9), generic(__unnamed_10), generic(__unnamed_11), generic(__unnamed_12), generic(__unnamed_13), generic(__unnamed_14), generic(__unnamed_15), generic(__unnamed_16), generic(__unnamed_17), generic(__unnamed_18), generic(__unnamed_19), generic(__unnamed_20), generic(__unnamed_21), generic(__unnamed_22), generic(__unnamed_23), generic(__unnamed_24), generic(__unnamed_25), generic(__unnamed_26), generic(__unnamed_27), generic(__unnamed_28), generic(__unnamed_29), generic(__unnamed_30), generic(__unnamed_31), generic(__unnamed_32), generic(__unnamed_33), generic(__unnamed_34), generic(__unnamed_35), generic(__unnamed_36), generic(__unnamed_37), generic(__unnamed_38), generic(__unnamed_39), generic(__unnamed_40), generic(__unnamed_41), generic(__unnamed_42), generic(__unnamed_43), generic(__unnamed_44), generic(__unnamed_32), generic(__unnamed_45), generic(__unnamed_46), generic(__unnamed_47), generic(__unnamed_48), generic(__unnamed_49), generic(__unnamed_50), generic(__unnamed_51), generic(__unnamed_52), generic(__unnamed_52), generic(__unnamed_53), generic(__unnamed_54), generic(__unnamed_55), generic(__unnamed_31), generic(__unnamed_56), generic(__unnamed_57), generic(__unnamed_31), generic(__unnamed_31), generic(__unnamed_58), generic(__unnamed_58), generic(__unnamed_59), generic(__unnamed_60), generic(__unnamed_61), generic(__unnamed_62), generic(__unnamed_63), generic(__unnamed_64), generic(__unnamed_65), generic(__unnamed_3), generic(__unnamed_66), generic(__unnamed_67), generic(__unnamed_46), generic(__unnamed_68), generic(__unnamed_69), generic(__unnamed_31), generic(__unnamed_50), generic(__unnamed_47), generic(__unnamed_48), generic(__unnamed_50), generic(__unnamed_47), generic(__unnamed_48), generic(__unnamed_70), generic(__unnamed_50), generic(__unnamed_47), generic(__unnamed_48), generic(__unnamed_71), generic(__unnamed_72), generic(__unnamed_46), generic(__unnamed_71), generic(__unnamed_72), generic(__unnamed_71), generic(__unnamed_72), generic(__unnamed_59), generic(__unnamed_73), generic(__unnamed_74), generic(__unnamed_58), generic(__unnamed_58), generic(__unnamed_59), generic(__unnamed_75), generic(__unnamed_46), generic(__unnamed_73), generic(__unnamed_74), generic(__unnamed_59), generic(__unnamed_73), generic(__unnamed_74), generic(__unnamed_76), generic(__unnamed_77), generic(__unnamed_46), generic(__unnamed_76), generic(__unnamed_77), generic(__unnamed_76), generic(__unnamed_77), generic(__unnamed_68), generic(__unnamed_69), generic(__unnamed_68), generic(__unnamed_69), generic(__unnamed_78), generic(__unnamed_79), generic(__unnamed_51)};
.visible .global .align 4 .u32 chpl_mem_numDescs = 122;
.visible .global .align 4 .b8 chpl_subclass_max_id[292] = {0, 0, 0, 0, 72, 0, 0, 0, 3, 0, 0, 0, 3, 0, 0, 0, 4, 0, 0, 0, 6, 0, 0, 0, 6, 0, 0, 0, 11, 0, 0, 0, 9, 0, 0, 0, 9, 0, 0, 0, 11, 0, 0, 0, 11, 0, 0, 0, 24, 0, 0, 0, 21, 0, 0, 0, 15, 0, 0, 0, 15, 0, 0, 0, 17, 0, 0, 0, 17, 0, 0, 0, 19, 0, 0, 0, 19, 0, 0, 0, 21, 0, 0, 0, 21, 0, 0, 0, 24, 0, 0, 0, 24, 0, 0, 0, 24, 0, 0, 0, 31, 0, 0, 0, 26, 0, 0, 0, 29, 0, 0, 0, 28, 0, 0, 0, 29, 0, 0, 0, 31, 0, 0, 0, 31, 0, 0, 0, 32, 0, 0, 0, 33, 0, 0, 0, 34, 0, 0, 0, 35, 0, 0, 0, 36, 0, 0, 0, 37, 0, 0, 0, 65, 0, 0, 0, 39, 0, 0, 0, 40, 0, 0, 0, 41, 0, 0, 0, 42, 0, 0, 0, 43, 0, 0, 0, 44, 0, 0, 0, 45, 0, 0, 0, 62, 0, 0, 0, 47, 0, 0, 0, 48, 0, 0, 0, 53, 0, 0, 0, 50, 0, 0, 0, 51, 0, 0, 0, 52, 0, 0, 0, 53, 0, 0, 0, 54, 0, 0, 0, 55, 0, 0, 0, 56, 0, 0, 0, 57, 0, 0, 0, 58, 0, 0, 0, 59, 0, 0, 0, 60, 0, 0, 0, 61, 0, 0, 0, 62, 0, 0, 0, 63, 0, 0, 0, 64, 0, 0, 0, 65, 0, 0, 0, 66, 0, 0, 0, 67, 0, 0, 0, 68, 0, 0, 0, 69, 0, 0, 0, 70, 0, 0, 0, 71, 0, 0, 0, 72, 0, 0, 0};
.global .align 1 .b8 __unnamed_80[1];
.visible .global .align 8 .u64 _cstr_literal_4113 = generic(__unnamed_80);
.global .align 1 .b8 __unnamed_81[10] = {82, 111, 111, 116, 67, 108, 97, 115, 115, 0};
.visible .global .align 8 .u64 _cstr_literal_4950 = generic(__unnamed_81);
.global .align 1 .b8 __unnamed_82[14] = {95, 69, 110, 100, 67, 111, 117, 110, 116, 66, 97, 115, 101, 0};
.visible .global .align 8 .u64 _cstr_literal_4951 = generic(__unnamed_82);
.global .align 1 .b8 __unnamed_83[9] = {66, 97, 115, 101, 68, 105, 115, 116, 0};
.visible .global .align 8 .u64 _cstr_literal_4952 = generic(__unnamed_83);
.global .align 1 .b8 __unnamed_84[8] = {66, 97, 115, 101, 68, 111, 109, 0};
.visible .global .align 8 .u64 _cstr_literal_4953 = generic(__unnamed_84);
.global .align 1 .b8 __unnamed_85[34] = {66, 97, 115, 101, 82, 101, 99, 116, 97, 110, 103, 117, 108, 97, 114, 68, 111, 109, 40, 49, 44, 105, 110, 116, 40, 54, 52, 41, 44, 111, 110, 101, 41, 0};
.visible .global .align 8 .u64 _cstr_literal_4954 = generic(__unnamed_85);
.global .align 1 .b8 __unnamed_86[34] = {66, 97, 115, 101, 82, 101, 99, 116, 97, 110, 103, 117, 108, 97, 114, 68, 111, 109, 40, 50, 44, 105, 110, 116, 40, 54, 52, 41, 44, 111, 110, 101, 41, 0};
.visible .global .align 8 .u64 _cstr_literal_4955 = generic(__unnamed_86);
.global .align 1 .b8 __unnamed_87[8] = {66, 97, 115, 101, 65, 114, 114, 0};
.visible .global .align 8 .u64 _cstr_literal_4956 = generic(__unnamed_87);
.global .align 1 .b8 __unnamed_88[64] = {66, 97, 115, 101, 82, 101, 99, 116, 97, 110, 103, 117, 108, 97, 114, 65, 114, 114, 40, 49, 44, 105, 110, 116, 40, 54, 52, 41, 44, 111, 110, 101, 44, 117, 110, 109, 97, 110, 97, 103, 101, 100, 32, 65, 98, 115, 116, 114, 97, 99, 116, 76, 111, 99, 97, 108, 101, 77, 111, 100, 101, 108, 41, 0};
.visible .global .align 8 .u64 _cstr_literal_4957 = generic(__unnamed_88);
.global .align 1 .b8 __unnamed_89[42] = {66, 97, 115, 101, 82, 101, 99, 116, 97, 110, 103, 117, 108, 97, 114, 65, 114, 114, 40, 49, 44, 105, 110, 116, 40, 54, 52, 41, 44, 111, 110, 101, 44, 105, 110, 116, 40, 54, 52, 41, 41, 0};
.visible .global .align 8 .u64 _cstr_literal_4958 = generic(__unnamed_89);
.global .align 1 .b8 __unnamed_90[41] = {66, 97, 115, 101, 82, 101, 99, 116, 97, 110, 103, 117, 108, 97, 114, 65, 114, 114, 40, 49, 44, 105, 110, 116, 40, 54, 52, 41, 44, 111, 110, 101, 44, 108, 111, 99, 97, 108, 101, 41, 0};
.visible .global .align 8 .u64 _cstr_literal_4959 = generic(__unnamed_90);
.global .align 1 .b8 __unnamed_91[43] = {66, 97, 115, 101, 82, 101, 99, 116, 97, 110, 103, 117, 108, 97, 114, 65, 114, 114, 40, 49, 44, 105, 110, 116, 40, 54, 52, 41, 44, 111, 110, 101, 44, 117, 105, 110, 116, 40, 54, 52, 41, 41, 0};
.visible .global .align 8 .u64 _cstr_literal_4960 = generic(__unnamed_91);
.global .align 1 .b8 __unnamed_92[43] = {66, 97, 115, 101, 82, 101, 99, 116, 97, 110, 103, 117, 108, 97, 114, 65, 114, 114, 40, 50, 44, 105, 110, 116, 40, 54, 52, 41, 44, 111, 110, 101, 44, 114, 101, 97, 108, 40, 54, 52, 41, 41, 0};
.visible .global .align 8 .u64 _cstr_literal_4961 = generic(__unnamed_92);
.global .align 1 .b8 __unnamed_93[11] = {66, 97, 115, 101, 76, 111, 99, 97, 108, 101, 0};
.visible .global .align 8 .u64 _cstr_literal_4962 = generic(__unnamed_93);
.global .align 1 .b8 __unnamed_94[20] = {65, 98, 115, 116, 114, 97, 99, 116, 76, 111, 99, 97, 108, 101, 77, 111, 100, 101, 108, 0};
.visible .global .align 8 .u64 _cstr_literal_4963 = generic(__unnamed_94);
.global .align 1 .b8 __unnamed_95[19] = {65, 98, 115, 116, 114, 97, 99, 116, 82, 111, 111, 116, 76, 111, 99, 97, 108, 101, 0};
.visible .global .align 8 .u64 _cstr_literal_4964 = generic(__unnamed_95);
.global .align 1 .b8 __unnamed_96[6] = {69, 114, 114, 111, 114, 0};
.visible .global .align 8 .u64 _cstr_literal_1329 = generic(__unnamed_96);
.global .align 1 .b8 __unnamed_97[16] = {67, 111, 110, 110, 101, 99, 116, 105, 111, 110, 69, 114, 114, 111, 114, 0};
.visible .global .align 8 .u64 _cstr_literal_4965 = generic(__unnamed_97);
.global .align 1 .b8 __unnamed_98[14] = {81, 105, 111, 80, 108, 117, 103, 105, 110, 70, 105, 108, 101, 0};
.visible .global .align 8 .u64 _cstr_literal_4966 = generic(__unnamed_98);
.global .align 1 .b8 __unnamed_99[17] = {81, 105, 111, 80, 108, 117, 103, 105, 110, 67, 104, 97, 110, 110, 101, 108, 0};
.visible .global .align 8 .u64 _cstr_literal_4967 = generic(__unnamed_99);
.global .align 1 .b8 __unnamed_100[9] = {84, 105, 109, 101, 122, 111, 110, 101, 0};
.visible .global .align 8 .u64 _cstr_literal_4968 = generic(__unnamed_100);
.visible .global .align 8 .u64 chpl_classNames[73] = {generic(__unnamed_80), generic(__unnamed_81), generic(__unnamed_82), generic(__unnamed_6), generic(__unnamed_62), generic(__unnamed_83), generic(__unnamed_38), generic(__unnamed_84), generic(__unnamed_85), generic(__unnamed_39), generic(__unnamed_86), generic(__unnamed_56), generic(__unnamed_87), generic(__unnamed_41), generic(__unnamed_88), generic(__unnamed_53), generic(__unnamed_89), generic(__unnamed_65), generic(__unnamed_90), generic(__unnamed_40), generic(__unnamed_91), generic(__unnamed_67), generic(__unnamed_61), generic(__unnamed_92), generic(__unnamed_57), generic(__unnamed_93), generic(__unnamed_7), generic(__unnamed_94), generic(__unnamed_54), generic(__unnamed_55), generic(__unnamed_95), generic(__unnamed_49), generic(__unnamed_5), generic(__unnamed_4), generic(__unnamed_3), generic(__unnamed_32), generic(__unnamed_29), generic(__unnamed_33), generic(__unnamed_96), generic(__unnamed_2), generic(__unnamed_78), generic(__unnamed_79), generic(__unnamed_1), generic(__unnamed_27), generic(__unnamed_37), generic(__unnamed_44), generic(__unnamed_26), generic(__unnamed_11), generic(__unnamed_12), generic(__unnamed_97), generic(__unnamed_13), generic(__unnamed_14), generic(__unnamed_15), generic(__unnamed_16), generic(__unnamed_17), generic(__unnamed_18), generic(__unnamed_19), generic(__unnamed_20), generic(__unnamed_21), generic(__unnamed_22), generic(__unnamed_23), generic(__unnamed_24), generic(__unnamed_25), generic(__unnamed_8), generic(__unnamed_9), generic(__unnamed_10), generic(__unnamed_98), generic(__unnamed_99), generic(__unnamed_64), generic(__unnamed_63), generic(__unnamed_28), generic(__unnamed_30), generic(__unnamed_100)};
.visible .global .align 8 .b8 chpl_finfo[16];
.visible .global .align 8 .b8 chpl_vmtable[8];
.visible .global .align 4 .u32 chpl_nodeID = -1;

.func chplDummyFunction()
{


	ret;

}
	// .globl	_local__makeIndexTuple_chpl
.visible .func _local__makeIndexTuple_chpl(
	.param .b64 _local__makeIndexTuple_chpl_param_0,
	.param .b64 _local__makeIndexTuple_chpl_param_1
)
{
	.local .align 8 .b8 	__local_depot1[24];
	.reg .b64 	%SP;
	.reg .b64 	%SPL;
	.reg .b64 	%rd<7>;

	mov.u64 	%SPL, __local_depot1;
	cvta.local.u64 	%SP, %SPL;
	ld.param.u64 	%rd2, [_local__makeIndexTuple_chpl_param_1];
	ld.param.u64 	%rd1, [_local__makeIndexTuple_chpl_param_0];
	st.u64 	[%SP+0], %rd1;
	st.u64 	[%SP+8], %rd2;
	bra.uni 	$L__BB1_1;
$L__BB1_1:
	ld.u64 	%rd3, [%SP+0];
	ld.u64 	%rd4, [%rd3];
	st.u64 	[%SP+16], %rd4;
	ld.u64 	%rd5, [%SP+8];
	ld.u64 	%rd6, [%SP+16];
	st.u64 	[%rd5], %rd6;
	ret;

}
	// .globl	_makeIndexTuple_chpl
.visible .func _makeIndexTuple_chpl(
	.param .b64 _makeIndexTuple_chpl_param_0,
	.param .b64 _makeIndexTuple_chpl_param_1
)
{
	.local .align 8 .b8 	__local_depot2[24];
	.reg .b64 	%SP;
	.reg .b64 	%SPL;
	.reg .b64 	%rd<7>;

	mov.u64 	%SPL, __local_depot2;
	cvta.local.u64 	%SP, %SPL;
	ld.param.u64 	%rd2, [_makeIndexTuple_chpl_param_1];
	ld.param.u64 	%rd1, [_makeIndexTuple_chpl_param_0];
	st.u64 	[%SP+0], %rd1;
	st.u64 	[%SP+8], %rd2;
	bra.uni 	$L__BB2_1;
$L__BB2_1:
	ld.u64 	%rd3, [%SP+0];
	ld.u64 	%rd4, [%rd3];
	st.u64 	[%SP+16], %rd4;
	ld.u64 	%rd5, [%SP+8];
	ld.u64 	%rd6, [%SP+16];
	st.u64 	[%rd5], %rd6;
	ret;

}
	// .globl	chpl_gpu_kernel_ChapelBase_line_1515_
.visible .entry chpl_gpu_kernel_ChapelBase_line_1515_(
	.param .u64 chpl_gpu_kernel_ChapelBase_line_1515__param_0,
	.param .u64 chpl_gpu_kernel_ChapelBase_line_1515__param_1,
	.param .u64 chpl_gpu_kernel_ChapelBase_line_1515__param_2
)
{
	.local .align 8 .b8 	__local_depot3[48];
	.reg .b64 	%SP;
	.reg .b64 	%SPL;
	.reg .pred 	%p<2>;
	.reg .b32 	%r<7>;
	.reg .b64 	%rd<21>;

	mov.u64 	%SPL, __local_depot3;
	cvta.local.u64 	%SP, %SPL;
	ld.param.u64 	%rd3, [chpl_gpu_kernel_ChapelBase_line_1515__param_2];
	ld.param.u64 	%rd2, [chpl_gpu_kernel_ChapelBase_line_1515__param_1];
	ld.param.u64 	%rd1, [chpl_gpu_kernel_ChapelBase_line_1515__param_0];
	cvta.to.global.u64 	%rd4, %rd3;
	cvta.global.u64 	%rd5, %rd4;
	st.u64 	[%SP+0], %rd1;
	st.u64 	[%SP+8], %rd2;
	st.u64 	[%SP+16], %rd5;
	bra.uni 	$L__BB3_1;
$L__BB3_1:
	{ // callseq 0, 0
	.reg .b32 temp_param_reg;
	.param .b32 retval0;
	call.uni (retval0), 
	_ZL21chpl_gpu_getBlockIdxXv, 
	(
	);
	ld.param.b32 	%r1, [retval0+0];
	} // callseq 0
	cvt.s64.s32 	%rd6, %r1;
	st.u64 	[%SP+24], %rd6;
	{ // callseq 1, 0
	.reg .b32 temp_param_reg;
	.param .b32 retval0;
	call.uni (retval0), 
	_ZL21chpl_gpu_getBlockDimXv, 
	(
	);
	ld.param.b32 	%r3, [retval0+0];
	} // callseq 1
	st.u32 	[%SP+32], %r3;
	{ // callseq 2, 0
	.reg .b32 temp_param_reg;
	.param .b32 retval0;
	call.uni (retval0), 
	_ZL22chpl_gpu_getThreadIdxXv, 
	(
	);
	ld.param.b32 	%r5, [retval0+0];
	} // callseq 2
	st.u32 	[%SP+36], %r5;
	ld.u64 	%rd7, [%SP+24];
	ld.s32 	%rd8, [%SP+32];
	mul.lo.s64 	%rd9, %rd7, %rd8;
	ld.s32 	%rd10, [%SP+36];
	add.s64 	%rd11, %rd9, %rd10;
	ld.u64 	%rd12, [%SP+0];
	add.s64 	%rd13, %rd11, %rd12;
	st.u64 	[%SP+40], %rd13;
	bra.uni 	$L__BB3_2;
$L__BB3_2:
	ld.u64 	%rd14, [%SP+40];
	ld.u64 	%rd15, [%SP+8];
	setp.le.s64 	%p1, %rd14, %rd15;
	@%p1 bra 	$L__BB3_5;
	bra.uni 	$L__BB3_3;
$L__BB3_3:
	bra.uni 	$L__BB3_4;
$L__BB3_4:
	bra.uni 	$L__BB3_6;
$L__BB3_5:
	ld.u64 	%rd16, [%SP+40];
	ld.u64 	%rd17, [%SP+16];
	shl.b64 	%rd18, %rd16, 3;
	add.s64 	%rd19, %rd17, %rd18;
	mov.u64 	%rd20, 0;
	st.u64 	[%rd19], %rd20;
	bra.uni 	$L__BB3_6;
$L__BB3_6:
	ret;

}
	// .globl	chpl_gpu_kernel_ChapelBase_line_1515_2
.visible .entry chpl_gpu_kernel_ChapelBase_line_1515_2(
	.param .u64 chpl_gpu_kernel_ChapelBase_line_1515_2_param_0,
	.param .u64 chpl_gpu_kernel_ChapelBase_line_1515_2_param_1,
	.param .u64 chpl_gpu_kernel_ChapelBase_line_1515_2_param_2
)
{
	.local .align 8 .b8 	__local_depot4[48];
	.reg .b64 	%SP;
	.reg .b64 	%SPL;
	.reg .pred 	%p<2>;
	.reg .b32 	%r<7>;
	.reg .b64 	%rd<21>;

	mov.u64 	%SPL, __local_depot4;
	cvta.local.u64 	%SP, %SPL;
	ld.param.u64 	%rd3, [chpl_gpu_kernel_ChapelBase_line_1515_2_param_2];
	ld.param.u64 	%rd2, [chpl_gpu_kernel_ChapelBase_line_1515_2_param_1];
	ld.param.u64 	%rd1, [chpl_gpu_kernel_ChapelBase_line_1515_2_param_0];
	cvta.to.global.u64 	%rd4, %rd3;
	cvta.global.u64 	%rd5, %rd4;
	st.u64 	[%SP+0], %rd1;
	st.u64 	[%SP+8], %rd2;
	st.u64 	[%SP+16], %rd5;
	bra.uni 	$L__BB4_1;
$L__BB4_1:
	{ // callseq 3, 0
	.reg .b32 temp_param_reg;
	.param .b32 retval0;
	call.uni (retval0), 
	_ZL21chpl_gpu_getBlockIdxXv, 
	(
	);
	ld.param.b32 	%r1, [retval0+0];
	} // callseq 3
	cvt.s64.s32 	%rd6, %r1;
	st.u64 	[%SP+24], %rd6;
	{ // callseq 4, 0
	.reg .b32 temp_param_reg;
	.param .b32 retval0;
	call.uni (retval0), 
	_ZL21chpl_gpu_getBlockDimXv, 
	(
	);
	ld.param.b32 	%r3, [retval0+0];
	} // callseq 4
	st.u32 	[%SP+32], %r3;
	{ // callseq 5, 0
	.reg .b32 temp_param_reg;
	.param .b32 retval0;
	call.uni (retval0), 
	_ZL22chpl_gpu_getThreadIdxXv, 
	(
	);
	ld.param.b32 	%r5, [retval0+0];
	} // callseq 5
	st.u32 	[%SP+36], %r5;
	ld.u64 	%rd7, [%SP+24];
	ld.s32 	%rd8, [%SP+32];
	mul.lo.s64 	%rd9, %rd7, %rd8;
	ld.s32 	%rd10, [%SP+36];
	add.s64 	%rd11, %rd9, %rd10;
	ld.u64 	%rd12, [%SP+0];
	add.s64 	%rd13, %rd11, %rd12;
	st.u64 	[%SP+40], %rd13;
	bra.uni 	$L__BB4_2;
$L__BB4_2:
	ld.u64 	%rd14, [%SP+40];
	ld.u64 	%rd15, [%SP+8];
	setp.le.s64 	%p1, %rd14, %rd15;
	@%p1 bra 	$L__BB4_5;
	bra.uni 	$L__BB4_3;
$L__BB4_3:
	bra.uni 	$L__BB4_4;
$L__BB4_4:
	bra.uni 	$L__BB4_6;
$L__BB4_5:
	ld.u64 	%rd16, [%SP+40];
	ld.u64 	%rd17, [%SP+16];
	shl.b64 	%rd18, %rd16, 3;
	add.s64 	%rd19, %rd17, %rd18;
	mov.u64 	%rd20, 0;
	st.u64 	[%rd19], %rd20;
	bra.uni 	$L__BB4_6;
$L__BB4_6:
	ret;

}
	// .globl	chpl_gpu_kernel_ChapelBase_line_1515_3
.visible .entry chpl_gpu_kernel_ChapelBase_line_1515_3(
	.param .u64 chpl_gpu_kernel_ChapelBase_line_1515_3_param_0,
	.param .u64 chpl_gpu_kernel_ChapelBase_line_1515_3_param_1,
	.param .u64 chpl_gpu_kernel_ChapelBase_line_1515_3_param_2
)
{
	.local .align 8 .b8 	__local_depot5[48];
	.reg .b64 	%SP;
	.reg .b64 	%SPL;
	.reg .pred 	%p<2>;
	.reg .b32 	%r<7>;
	.reg .b64 	%rd<21>;

	mov.u64 	%SPL, __local_depot5;
	cvta.local.u64 	%SP, %SPL;
	ld.param.u64 	%rd3, [chpl_gpu_kernel_ChapelBase_line_1515_3_param_2];
	ld.param.u64 	%rd2, [chpl_gpu_kernel_ChapelBase_line_1515_3_param_1];
	ld.param.u64 	%rd1, [chpl_gpu_kernel_ChapelBase_line_1515_3_param_0];
	cvta.to.global.u64 	%rd4, %rd3;
	cvta.global.u64 	%rd5, %rd4;
	st.u64 	[%SP+0], %rd1;
	st.u64 	[%SP+8], %rd2;
	st.u64 	[%SP+16], %rd5;
	bra.uni 	$L__BB5_1;
$L__BB5_1:
	{ // callseq 6, 0
	.reg .b32 temp_param_reg;
	.param .b32 retval0;
	call.uni (retval0), 
	_ZL21chpl_gpu_getBlockIdxXv, 
	(
	);
	ld.param.b32 	%r1, [retval0+0];
	} // callseq 6
	cvt.s64.s32 	%rd6, %r1;
	st.u64 	[%SP+24], %rd6;
	{ // callseq 7, 0
	.reg .b32 temp_param_reg;
	.param .b32 retval0;
	call.uni (retval0), 
	_ZL21chpl_gpu_getBlockDimXv, 
	(
	);
	ld.param.b32 	%r3, [retval0+0];
	} // callseq 7
	st.u32 	[%SP+32], %r3;
	{ // callseq 8, 0
	.reg .b32 temp_param_reg;
	.param .b32 retval0;
	call.uni (retval0), 
	_ZL22chpl_gpu_getThreadIdxXv, 
	(
	);
	ld.param.b32 	%r5, [retval0+0];
	} // callseq 8
	st.u32 	[%SP+36], %r5;
	ld.u64 	%rd7, [%SP+24];
	ld.s32 	%rd8, [%SP+32];
	mul.lo.s64 	%rd9, %rd7, %rd8;
	ld.s32 	%rd10, [%SP+36];
	add.s64 	%rd11, %rd9, %rd10;
	ld.u64 	%rd12, [%SP+0];
	add.s64 	%rd13, %rd11, %rd12;
	st.u64 	[%SP+40], %rd13;
	bra.uni 	$L__BB5_2;
$L__BB5_2:
	ld.u64 	%rd14, [%SP+40];
	ld.u64 	%rd15, [%SP+8];
	setp.le.s64 	%p1, %rd14, %rd15;
	@%p1 bra 	$L__BB5_5;
	bra.uni 	$L__BB5_3;
$L__BB5_3:
	bra.uni 	$L__BB5_4;
$L__BB5_4:
	bra.uni 	$L__BB5_6;
$L__BB5_5:
	ld.u64 	%rd16, [%SP+40];
	ld.u64 	%rd17, [%SP+16];
	shl.b64 	%rd18, %rd16, 3;
	add.s64 	%rd19, %rd17, %rd18;
	mov.u64 	%rd20, 0;
	st.u64 	[%rd19], %rd20;
	bra.uni 	$L__BB5_6;
$L__BB5_6:
	ret;

}
	// .globl	chpl_gpu_kernel_ChapelBase_line_1515_4
.visible .entry chpl_gpu_kernel_ChapelBase_line_1515_4(
	.param .u64 chpl_gpu_kernel_ChapelBase_line_1515_4_param_0,
	.param .u64 chpl_gpu_kernel_ChapelBase_line_1515_4_param_1,
	.param .u64 chpl_gpu_kernel_ChapelBase_line_1515_4_param_2,
	.param .u64 chpl_gpu_kernel_ChapelBase_line_1515_4_param_3,
	.param .u64 chpl_gpu_kernel_ChapelBase_line_1515_4_param_4,
	.param .u32 chpl_gpu_kernel_ChapelBase_line_1515_4_param_5
)
{
	.local .align 8 .b8 	__local_depot6[112];
	.reg .b64 	%SP;
	.reg .b64 	%SPL;
	.reg .pred 	%p<2>;
	.reg .b32 	%r<17>;
	.reg .b64 	%rd<35>;

	mov.u64 	%SPL, __local_depot6;
	cvta.local.u64 	%SP, %SPL;
	ld.param.u32 	%r1, [chpl_gpu_kernel_ChapelBase_line_1515_4_param_5];
	ld.param.u64 	%rd5, [chpl_gpu_kernel_ChapelBase_line_1515_4_param_4];
	ld.param.u64 	%rd4, [chpl_gpu_kernel_ChapelBase_line_1515_4_param_3];
	ld.param.u64 	%rd3, [chpl_gpu_kernel_ChapelBase_line_1515_4_param_2];
	ld.param.u64 	%rd2, [chpl_gpu_kernel_ChapelBase_line_1515_4_param_1];
	ld.param.u64 	%rd1, [chpl_gpu_kernel_ChapelBase_line_1515_4_param_0];
	cvta.to.global.u64 	%rd6, %rd4;
	cvta.global.u64 	%rd7, %rd6;
	cvta.to.global.u64 	%rd8, %rd3;
	cvta.global.u64 	%rd9, %rd8;
	st.u64 	[%SP+0], %rd1;
	st.u64 	[%SP+8], %rd2;
	st.u64 	[%SP+16], %rd9;
	st.u64 	[%SP+24], %rd7;
	st.u64 	[%SP+32], %rd5;
	st.u32 	[%SP+40], %r1;
	mov.u64 	%rd10, 0;
	st.u64 	[%SP+72], %rd10;
	add.u64 	%rd11, %SP, 80;
	or.b64  	%rd12, %rd11, 4;
	mov.u32 	%r2, 0;
	st.u32 	[%rd12], %r2;
	st.u64 	[%SP+88], %rd10;
	st.u32 	[%SP+80], %r2;
	bra.uni 	$L__BB6_1;
$L__BB6_1:
	{ // callseq 9, 0
	.reg .b32 temp_param_reg;
	.param .b32 retval0;
	call.uni (retval0), 
	_ZL21chpl_gpu_getBlockIdxXv, 
	(
	);
	ld.param.b32 	%r3, [retval0+0];
	} // callseq 9
	cvt.s64.s32 	%rd13, %r3;
	st.u64 	[%SP+48], %rd13;
	{ // callseq 10, 0
	.reg .b32 temp_param_reg;
	.param .b32 retval0;
	call.uni (retval0), 
	_ZL21chpl_gpu_getBlockDimXv, 
	(
	);
	ld.param.b32 	%r5, [retval0+0];
	} // callseq 10
	st.u32 	[%SP+56], %r5;
	{ // callseq 11, 0
	.reg .b32 temp_param_reg;
	.param .b32 retval0;
	call.uni (retval0), 
	_ZL22chpl_gpu_getThreadIdxXv, 
	(
	);
	ld.param.b32 	%r7, [retval0+0];
	} // callseq 11
	st.u32 	[%SP+60], %r7;
	ld.u64 	%rd14, [%SP+48];
	ld.s32 	%rd15, [%SP+56];
	mul.lo.s64 	%rd16, %rd14, %rd15;
	ld.s32 	%rd17, [%SP+60];
	add.s64 	%rd18, %rd16, %rd17;
	ld.u64 	%rd19, [%SP+0];
	add.s64 	%rd20, %rd18, %rd19;
	st.u64 	[%SP+64], %rd20;
	bra.uni 	$L__BB6_2;
$L__BB6_2:
	ld.u64 	%rd21, [%SP+64];
	ld.u64 	%rd22, [%SP+8];
	setp.le.s64 	%p1, %rd21, %rd22;
	@%p1 bra 	$L__BB6_5;
	bra.uni 	$L__BB6_3;
$L__BB6_3:
	bra.uni 	$L__BB6_4;
$L__BB6_4:
	bra.uni 	$L__BB6_6;
$L__BB6_5:
	mov.u64 	%rd23, 0;
	st.u64 	[%SP+72], %rd23;
	{ // callseq 12, 0
	.reg .b32 temp_param_reg;
	.param .align 16 .b8 retval0[8];
	call.uni (retval0), 
	_ZL20chpl_gen_getLocaleIDv, 
	(
	);
	ld.param.v2.b32 	{%r9, %r10}, [retval0+0];
	} // callseq 12
	ld.u64 	%rd24, [%SP+72];
	st.u64 	[%SP+104], %rd24;
	add.u64 	%rd25, %SP, 96;
	or.b64  	%rd26, %rd25, 4;
	st.u32 	[%rd26], %r10;
	st.u32 	[%SP+96], %r9;
	ld.u32 	%r13, [%rd26];
	ld.u32 	%r14, [%SP+96];
	ld.u64 	%rd27, [%SP+104];
	add.u64 	%rd28, %SP, 80;
	or.b64  	%rd29, %rd28, 4;
	st.u32 	[%rd29], %r13;
	st.u64 	[%SP+88], %rd27;
	st.u32 	[%SP+80], %r14;
	ld.u64 	%rd30, [%SP+64];
	ld.u64 	%rd31, [%SP+24];
	shl.b64 	%rd32, %rd30, 4;
	add.s64 	%rd33, %rd31, %rd32;
	ld.u32 	%r15, [%rd29];
	ld.u32 	%r16, [%SP+80];
	ld.u64 	%rd34, [%SP+88];
	st.u64 	[%rd33+8], %rd34;
	st.u32 	[%rd33+4], %r15;
	st.u32 	[%rd33], %r16;
	bra.uni 	$L__BB6_6;
$L__BB6_6:
	ret;

}
	// .globl	chpl_gpu_kernel_ChapelBase_line_1524_
.visible .entry chpl_gpu_kernel_ChapelBase_line_1524_(
	.param .u64 chpl_gpu_kernel_ChapelBase_line_1524__param_0,
	.param .u64 chpl_gpu_kernel_ChapelBase_line_1524__param_1,
	.param .u64 chpl_gpu_kernel_ChapelBase_line_1524__param_2,
	.param .u64 chpl_gpu_kernel_ChapelBase_line_1524__param_3,
	.param .u64 chpl_gpu_kernel_ChapelBase_line_1524__param_4,
	.param .u32 chpl_gpu_kernel_ChapelBase_line_1524__param_5
)
{
	.local .align 8 .b8 	__local_depot7[112];
	.reg .b64 	%SP;
	.reg .b64 	%SPL;
	.reg .pred 	%p<2>;
	.reg .b32 	%r<17>;
	.reg .b64 	%rd<35>;

	mov.u64 	%SPL, __local_depot7;
	cvta.local.u64 	%SP, %SPL;
	ld.param.u32 	%r1, [chpl_gpu_kernel_ChapelBase_line_1524__param_5];
	ld.param.u64 	%rd5, [chpl_gpu_kernel_ChapelBase_line_1524__param_4];
	ld.param.u64 	%rd4, [chpl_gpu_kernel_ChapelBase_line_1524__param_3];
	ld.param.u64 	%rd3, [chpl_gpu_kernel_ChapelBase_line_1524__param_2];
	ld.param.u64 	%rd2, [chpl_gpu_kernel_ChapelBase_line_1524__param_1];
	ld.param.u64 	%rd1, [chpl_gpu_kernel_ChapelBase_line_1524__param_0];
	cvta.to.global.u64 	%rd6, %rd4;
	cvta.global.u64 	%rd7, %rd6;
	cvta.to.global.u64 	%rd8, %rd3;
	cvta.global.u64 	%rd9, %rd8;
	st.u64 	[%SP+0], %rd1;
	st.u64 	[%SP+8], %rd2;
	st.u64 	[%SP+16], %rd9;
	st.u64 	[%SP+24], %rd7;
	st.u64 	[%SP+32], %rd5;
	st.u32 	[%SP+40], %r1;
	mov.u64 	%rd10, 0;
	st.u64 	[%SP+72], %rd10;
	add.u64 	%rd11, %SP, 80;
	or.b64  	%rd12, %rd11, 4;
	mov.u32 	%r2, 0;
	st.u32 	[%rd12], %r2;
	st.u64 	[%SP+88], %rd10;
	st.u32 	[%SP+80], %r2;
	bra.uni 	$L__BB7_1;
$L__BB7_1:
	{ // callseq 13, 0
	.reg .b32 temp_param_reg;
	.param .b32 retval0;
	call.uni (retval0), 
	_ZL21chpl_gpu_getBlockIdxXv, 
	(
	);
	ld.param.b32 	%r3, [retval0+0];
	} // callseq 13
	cvt.s64.s32 	%rd13, %r3;
	st.u64 	[%SP+48], %rd13;
	{ // callseq 14, 0
	.reg .b32 temp_param_reg;
	.param .b32 retval0;
	call.uni (retval0), 
	_ZL21chpl_gpu_getBlockDimXv, 
	(
	);
	ld.param.b32 	%r5, [retval0+0];
	} // callseq 14
	st.u32 	[%SP+56], %r5;
	{ // callseq 15, 0
	.reg .b32 temp_param_reg;
	.param .b32 retval0;
	call.uni (retval0), 
	_ZL22chpl_gpu_getThreadIdxXv, 
	(
	);
	ld.param.b32 	%r7, [retval0+0];
	} // callseq 15
	st.u32 	[%SP+60], %r7;
	ld.u64 	%rd14, [%SP+48];
	ld.s32 	%rd15, [%SP+56];
	mul.lo.s64 	%rd16, %rd14, %rd15;
	ld.s32 	%rd17, [%SP+60];
	add.s64 	%rd18, %rd16, %rd17;
	ld.u64 	%rd19, [%SP+0];
	add.s64 	%rd20, %rd18, %rd19;
	st.u64 	[%SP+64], %rd20;
	bra.uni 	$L__BB7_2;
$L__BB7_2:
	ld.u64 	%rd21, [%SP+64];
	ld.u64 	%rd22, [%SP+8];
	setp.le.s64 	%p1, %rd21, %rd22;
	@%p1 bra 	$L__BB7_5;
	bra.uni 	$L__BB7_3;
$L__BB7_3:
	bra.uni 	$L__BB7_4;
$L__BB7_4:
	bra.uni 	$L__BB7_6;
$L__BB7_5:
	mov.u64 	%rd23, 0;
	st.u64 	[%SP+72], %rd23;
	{ // callseq 16, 0
	.reg .b32 temp_param_reg;
	.param .align 16 .b8 retval0[8];
	call.uni (retval0), 
	_ZL20chpl_gen_getLocaleIDv, 
	(
	);
	ld.param.v2.b32 	{%r9, %r10}, [retval0+0];
	} // callseq 16
	ld.u64 	%rd24, [%SP+72];
	st.u64 	[%SP+104], %rd24;
	add.u64 	%rd25, %SP, 96;
	or.b64  	%rd26, %rd25, 4;
	st.u32 	[%rd26], %r10;
	st.u32 	[%SP+96], %r9;
	ld.u32 	%r13, [%rd26];
	ld.u32 	%r14, [%SP+96];
	ld.u64 	%rd27, [%SP+104];
	add.u64 	%rd28, %SP, 80;
	or.b64  	%rd29, %rd28, 4;
	st.u32 	[%rd29], %r13;
	st.u64 	[%SP+88], %rd27;
	st.u32 	[%SP+80], %r14;
	ld.u64 	%rd30, [%SP+64];
	ld.u64 	%rd31, [%SP+24];
	shl.b64 	%rd32, %rd30, 4;
	add.s64 	%rd33, %rd31, %rd32;
	ld.u32 	%r15, [%rd29];
	ld.u32 	%r16, [%SP+80];
	ld.u64 	%rd34, [%SP+88];
	st.u64 	[%rd33+8], %rd34;
	st.u32 	[%rd33+4], %r15;
	st.u32 	[%rd33], %r16;
	bra.uni 	$L__BB7_6;
$L__BB7_6:
	ret;

}
	// .globl	chpl_gpu_kernel_ChapelBase_line_1524_2
.visible .entry chpl_gpu_kernel_ChapelBase_line_1524_2(
	.param .u64 chpl_gpu_kernel_ChapelBase_line_1524_2_param_0,
	.param .u64 chpl_gpu_kernel_ChapelBase_line_1524_2_param_1,
	.param .u64 chpl_gpu_kernel_ChapelBase_line_1524_2_param_2
)
{
	.local .align 8 .b8 	__local_depot8[48];
	.reg .b64 	%SP;
	.reg .b64 	%SPL;
	.reg .pred 	%p<2>;
	.reg .b32 	%r<7>;
	.reg .b64 	%rd<21>;

	mov.u64 	%SPL, __local_depot8;
	cvta.local.u64 	%SP, %SPL;
	ld.param.u64 	%rd3, [chpl_gpu_kernel_ChapelBase_line_1524_2_param_2];
	ld.param.u64 	%rd2, [chpl_gpu_kernel_ChapelBase_line_1524_2_param_1];
	ld.param.u64 	%rd1, [chpl_gpu_kernel_ChapelBase_line_1524_2_param_0];
	cvta.to.global.u64 	%rd4, %rd3;
	cvta.global.u64 	%rd5, %rd4;
	st.u64 	[%SP+0], %rd1;
	st.u64 	[%SP+8], %rd2;
	st.u64 	[%SP+16], %rd5;
	bra.uni 	$L__BB8_1;
$L__BB8_1:
	{ // callseq 17, 0
	.reg .b32 temp_param_reg;
	.param .b32 retval0;
	call.uni (retval0), 
	_ZL21chpl_gpu_getBlockIdxXv, 
	(
	);
	ld.param.b32 	%r1, [retval0+0];
	} // callseq 17
	cvt.s64.s32 	%rd6, %r1;
	st.u64 	[%SP+24], %rd6;
	{ // callseq 18, 0
	.reg .b32 temp_param_reg;
	.param .b32 retval0;
	call.uni (retval0), 
	_ZL21chpl_gpu_getBlockDimXv, 
	(
	);
	ld.param.b32 	%r3, [retval0+0];
	} // callseq 18
	st.u32 	[%SP+32], %r3;
	{ // callseq 19, 0
	.reg .b32 temp_param_reg;
	.param .b32 retval0;
	call.uni (retval0), 
	_ZL22chpl_gpu_getThreadIdxXv, 
	(
	);
	ld.param.b32 	%r5, [retval0+0];
	} // callseq 19
	st.u32 	[%SP+36], %r5;
	ld.u64 	%rd7, [%SP+24];
	ld.s32 	%rd8, [%SP+32];
	mul.lo.s64 	%rd9, %rd7, %rd8;
	ld.s32 	%rd10, [%SP+36];
	add.s64 	%rd11, %rd9, %rd10;
	ld.u64 	%rd12, [%SP+0];
	add.s64 	%rd13, %rd11, %rd12;
	st.u64 	[%SP+40], %rd13;
	bra.uni 	$L__BB8_2;
$L__BB8_2:
	ld.u64 	%rd14, [%SP+40];
	ld.u64 	%rd15, [%SP+8];
	setp.le.s64 	%p1, %rd14, %rd15;
	@%p1 bra 	$L__BB8_5;
	bra.uni 	$L__BB8_3;
$L__BB8_3:
	bra.uni 	$L__BB8_4;
$L__BB8_4:
	bra.uni 	$L__BB8_6;
$L__BB8_5:
	ld.u64 	%rd16, [%SP+40];
	ld.u64 	%rd17, [%SP+16];
	shl.b64 	%rd18, %rd16, 3;
	add.s64 	%rd19, %rd17, %rd18;
	mov.u64 	%rd20, 0;
	st.u64 	[%rd19], %rd20;
	bra.uni 	$L__BB8_6;
$L__BB8_6:
	ret;

}
	// .globl	chpl_gpu_kernel_ChapelBase_line_1524_3
.visible .entry chpl_gpu_kernel_ChapelBase_line_1524_3(
	.param .u64 chpl_gpu_kernel_ChapelBase_line_1524_3_param_0,
	.param .u64 chpl_gpu_kernel_ChapelBase_line_1524_3_param_1,
	.param .u64 chpl_gpu_kernel_ChapelBase_line_1524_3_param_2
)
{
	.local .align 8 .b8 	__local_depot9[48];
	.reg .b64 	%SP;
	.reg .b64 	%SPL;
	.reg .pred 	%p<2>;
	.reg .b32 	%r<7>;
	.reg .b64 	%rd<21>;

	mov.u64 	%SPL, __local_depot9;
	cvta.local.u64 	%SP, %SPL;
	ld.param.u64 	%rd3, [chpl_gpu_kernel_ChapelBase_line_1524_3_param_2];
	ld.param.u64 	%rd2, [chpl_gpu_kernel_ChapelBase_line_1524_3_param_1];
	ld.param.u64 	%rd1, [chpl_gpu_kernel_ChapelBase_line_1524_3_param_0];
	cvta.to.global.u64 	%rd4, %rd3;
	cvta.global.u64 	%rd5, %rd4;
	st.u64 	[%SP+0], %rd1;
	st.u64 	[%SP+8], %rd2;
	st.u64 	[%SP+16], %rd5;
	bra.uni 	$L__BB9_1;
$L__BB9_1:
	{ // callseq 20, 0
	.reg .b32 temp_param_reg;
	.param .b32 retval0;
	call.uni (retval0), 
	_ZL21chpl_gpu_getBlockIdxXv, 
	(
	);
	ld.param.b32 	%r1, [retval0+0];
	} // callseq 20
	cvt.s64.s32 	%rd6, %r1;
	st.u64 	[%SP+24], %rd6;
	{ // callseq 21, 0
	.reg .b32 temp_param_reg;
	.param .b32 retval0;
	call.uni (retval0), 
	_ZL21chpl_gpu_getBlockDimXv, 
	(
	);
	ld.param.b32 	%r3, [retval0+0];
	} // callseq 21
	st.u32 	[%SP+32], %r3;
	{ // callseq 22, 0
	.reg .b32 temp_param_reg;
	.param .b32 retval0;
	call.uni (retval0), 
	_ZL22chpl_gpu_getThreadIdxXv, 
	(
	);
	ld.param.b32 	%r5, [retval0+0];
	} // callseq 22
	st.u32 	[%SP+36], %r5;
	ld.u64 	%rd7, [%SP+24];
	ld.s32 	%rd8, [%SP+32];
	mul.lo.s64 	%rd9, %rd7, %rd8;
	ld.s32 	%rd10, [%SP+36];
	add.s64 	%rd11, %rd9, %rd10;
	ld.u64 	%rd12, [%SP+0];
	add.s64 	%rd13, %rd11, %rd12;
	st.u64 	[%SP+40], %rd13;
	bra.uni 	$L__BB9_2;
$L__BB9_2:
	ld.u64 	%rd14, [%SP+40];
	ld.u64 	%rd15, [%SP+8];
	setp.le.s64 	%p1, %rd14, %rd15;
	@%p1 bra 	$L__BB9_5;
	bra.uni 	$L__BB9_3;
$L__BB9_3:
	bra.uni 	$L__BB9_4;
$L__BB9_4:
	bra.uni 	$L__BB9_6;
$L__BB9_5:
	ld.u64 	%rd16, [%SP+40];
	ld.u64 	%rd17, [%SP+16];
	shl.b64 	%rd18, %rd16, 3;
	add.s64 	%rd19, %rd17, %rd18;
	mov.u64 	%rd20, 0;
	st.u64 	[%rd19], %rd20;
	bra.uni 	$L__BB9_6;
$L__BB9_6:
	ret;

}
	// .globl	chpl_gpu_kernel_ChapelBase_line_1524_4
.visible .entry chpl_gpu_kernel_ChapelBase_line_1524_4(
	.param .u64 chpl_gpu_kernel_ChapelBase_line_1524_4_param_0,
	.param .u64 chpl_gpu_kernel_ChapelBase_line_1524_4_param_1,
	.param .u64 chpl_gpu_kernel_ChapelBase_line_1524_4_param_2
)
{
	.local .align 8 .b8 	__local_depot10[48];
	.reg .b64 	%SP;
	.reg .b64 	%SPL;
	.reg .pred 	%p<2>;
	.reg .b32 	%r<7>;
	.reg .b64 	%rd<21>;

	mov.u64 	%SPL, __local_depot10;
	cvta.local.u64 	%SP, %SPL;
	ld.param.u64 	%rd3, [chpl_gpu_kernel_ChapelBase_line_1524_4_param_2];
	ld.param.u64 	%rd2, [chpl_gpu_kernel_ChapelBase_line_1524_4_param_1];
	ld.param.u64 	%rd1, [chpl_gpu_kernel_ChapelBase_line_1524_4_param_0];
	cvta.to.global.u64 	%rd4, %rd3;
	cvta.global.u64 	%rd5, %rd4;
	st.u64 	[%SP+0], %rd1;
	st.u64 	[%SP+8], %rd2;
	st.u64 	[%SP+16], %rd5;
	bra.uni 	$L__BB10_1;
$L__BB10_1:
	{ // callseq 23, 0
	.reg .b32 temp_param_reg;
	.param .b32 retval0;
	call.uni (retval0), 
	_ZL21chpl_gpu_getBlockIdxXv, 
	(
	);
	ld.param.b32 	%r1, [retval0+0];
	} // callseq 23
	cvt.s64.s32 	%rd6, %r1;
	st.u64 	[%SP+24], %rd6;
	{ // callseq 24, 0
	.reg .b32 temp_param_reg;
	.param .b32 retval0;
	call.uni (retval0), 
	_ZL21chpl_gpu_getBlockDimXv, 
	(
	);
	ld.param.b32 	%r3, [retval0+0];
	} // callseq 24
	st.u32 	[%SP+32], %r3;
	{ // callseq 25, 0
	.reg .b32 temp_param_reg;
	.param .b32 retval0;
	call.uni (retval0), 
	_ZL22chpl_gpu_getThreadIdxXv, 
	(
	);
	ld.param.b32 	%r5, [retval0+0];
	} // callseq 25
	st.u32 	[%SP+36], %r5;
	ld.u64 	%rd7, [%SP+24];
	ld.s32 	%rd8, [%SP+32];
	mul.lo.s64 	%rd9, %rd7, %rd8;
	ld.s32 	%rd10, [%SP+36];
	add.s64 	%rd11, %rd9, %rd10;
	ld.u64 	%rd12, [%SP+0];
	add.s64 	%rd13, %rd11, %rd12;
	st.u64 	[%SP+40], %rd13;
	bra.uni 	$L__BB10_2;
$L__BB10_2:
	ld.u64 	%rd14, [%SP+40];
	ld.u64 	%rd15, [%SP+8];
	setp.le.s64 	%p1, %rd14, %rd15;
	@%p1 bra 	$L__BB10_5;
	bra.uni 	$L__BB10_3;
$L__BB10_3:
	bra.uni 	$L__BB10_4;
$L__BB10_4:
	bra.uni 	$L__BB10_6;
$L__BB10_5:
	ld.u64 	%rd16, [%SP+40];
	ld.u64 	%rd17, [%SP+16];
	shl.b64 	%rd18, %rd16, 3;
	add.s64 	%rd19, %rd17, %rd18;
	mov.u64 	%rd20, 0;
	st.u64 	[%rd19], %rd20;
	bra.uni 	$L__BB10_6;
$L__BB10_6:
	ret;

}
	// .globl	chpl_gpu_kernel_ChapelBase_line_1712_
.visible .entry chpl_gpu_kernel_ChapelBase_line_1712_(
	.param .u64 chpl_gpu_kernel_ChapelBase_line_1712__param_0,
	.param .u64 chpl_gpu_kernel_ChapelBase_line_1712__param_1,
	.param .u64 chpl_gpu_kernel_ChapelBase_line_1712__param_2
)
{
	.local .align 8 .b8 	__local_depot11[88];
	.reg .b64 	%SP;
	.reg .b64 	%SPL;
	.reg .pred 	%p<2>;
	.reg .b32 	%r<16>;
	.reg .b64 	%rd<30>;

	mov.u64 	%SPL, __local_depot11;
	cvta.local.u64 	%SP, %SPL;
	ld.param.u64 	%rd3, [chpl_gpu_kernel_ChapelBase_line_1712__param_2];
	ld.param.u64 	%rd2, [chpl_gpu_kernel_ChapelBase_line_1712__param_1];
	ld.param.u64 	%rd1, [chpl_gpu_kernel_ChapelBase_line_1712__param_0];
	cvta.to.global.u64 	%rd4, %rd3;
	cvta.global.u64 	%rd5, %rd4;
	st.u64 	[%SP+0], %rd1;
	st.u64 	[%SP+8], %rd2;
	st.u64 	[%SP+16], %rd5;
	mov.u64 	%rd6, 0;
	st.u64 	[%SP+48], %rd6;
	add.u64 	%rd7, %SP, 56;
	or.b64  	%rd8, %rd7, 4;
	mov.u32 	%r1, 0;
	st.u32 	[%rd8], %r1;
	st.u64 	[%SP+64], %rd6;
	st.u32 	[%SP+56], %r1;
	bra.uni 	$L__BB11_1;
$L__BB11_1:
	{ // callseq 26, 0
	.reg .b32 temp_param_reg;
	.param .b32 retval0;
	call.uni (retval0), 
	_ZL21chpl_gpu_getBlockIdxXv, 
	(
	);
	ld.param.b32 	%r2, [retval0+0];
	} // callseq 26
	cvt.s64.s32 	%rd9, %r2;
	st.u64 	[%SP+24], %rd9;
	{ // callseq 27, 0
	.reg .b32 temp_param_reg;
	.param .b32 retval0;
	call.uni (retval0), 
	_ZL21chpl_gpu_getBlockDimXv, 
	(
	);
	ld.param.b32 	%r4, [retval0+0];
	} // callseq 27
	st.u32 	[%SP+32], %r4;
	{ // callseq 28, 0
	.reg .b32 temp_param_reg;
	.param .b32 retval0;
	call.uni (retval0), 
	_ZL22chpl_gpu_getThreadIdxXv, 
	(
	);
	ld.param.b32 	%r6, [retval0+0];
	} // callseq 28
	st.u32 	[%SP+36], %r6;
	ld.u64 	%rd10, [%SP+24];
	ld.s32 	%rd11, [%SP+32];
	mul.lo.s64 	%rd12, %rd10, %rd11;
	ld.s32 	%rd13, [%SP+36];
	add.s64 	%rd14, %rd12, %rd13;
	ld.u64 	%rd15, [%SP+0];
	add.s64 	%rd16, %rd14, %rd15;
	st.u64 	[%SP+40], %rd16;
	bra.uni 	$L__BB11_2;
$L__BB11_2:
	ld.u64 	%rd17, [%SP+40];
	ld.u64 	%rd18, [%SP+8];
	setp.le.s64 	%p1, %rd17, %rd18;
	@%p1 bra 	$L__BB11_5;
	bra.uni 	$L__BB11_3;
$L__BB11_3:
	bra.uni 	$L__BB11_4;
$L__BB11_4:
	bra.uni 	$L__BB11_6;
$L__BB11_5:
	ld.u64 	%rd19, [%SP+40];
	ld.u64 	%rd20, [%SP+16];
	shl.b64 	%rd21, %rd19, 4;
	add.s64 	%rd22, %rd20, %rd21;
	st.u64 	[%SP+48], %rd22;
	{ // callseq 29, 0
	.reg .b32 temp_param_reg;
	.param .align 16 .b8 retval0[8];
	call.uni (retval0), 
	_ZL20chpl_gen_getLocaleIDv, 
	(
	);
	ld.param.v2.b32 	{%r8, %r9}, [retval0+0];
	} // callseq 29
	ld.u64 	%rd23, [%SP+48];
	st.u64 	[%SP+80], %rd23;
	add.u64 	%rd24, %SP, 72;
	or.b64  	%rd25, %rd24, 4;
	st.u32 	[%rd25], %r9;
	st.u32 	[%SP+72], %r8;
	ld.u32 	%r12, [%rd25];
	ld.u32 	%r13, [%SP+72];
	ld.u64 	%rd26, [%SP+80];
	add.u64 	%rd27, %SP, 56;
	or.b64  	%rd28, %rd27, 4;
	st.u32 	[%rd28], %r12;
	st.u64 	[%SP+64], %rd26;
	st.u32 	[%SP+56], %r13;
	ld.u32 	%r14, [%rd28];
	ld.u64 	%rd29, [%SP+64];
	ld.u32 	%r15, [%SP+56];
	{ // callseq 30, 0
	.reg .b32 temp_param_reg;
	.param .align 8 .b8 param0[16];
	st.param.v2.b32 	[param0+0], {%r15, %r14};
	st.param.b64 	[param0+8], %rd29;
	call.uni 
	_local_deinit_chpl, 
	(
	param0
	);
	} // callseq 30
	bra.uni 	$L__BB11_6;
$L__BB11_6:
	ret;

}
	// .globl	_local_contains_chpl
.visible .func  (.param .b32 func_retval0) _local_contains_chpl(
	.param .b64 _local_contains_chpl_param_0,
	.param .b64 _local_contains_chpl_param_1
)
{
	.local .align 8 .b8 	__local_depot12[64];
	.reg .b64 	%SP;
	.reg .b64 	%SPL;
	.reg .pred 	%p<2>;
	.reg .b16 	%rs<2>;
	.reg .b32 	%r<7>;
	.reg .b64 	%rd<16>;

	mov.u64 	%SPL, __local_depot12;
	cvta.local.u64 	%SP, %SPL;
	ld.param.u64 	%rd2, [_local_contains_chpl_param_1];
	ld.param.u64 	%rd1, [_local_contains_chpl_param_0];
	st.u64 	[%SP+0], %rd1;
	st.u64 	[%SP+8], %rd2;
	mov.u64 	%rd3, 0;
	st.u64 	[%SP+16], %rd3;
	add.u64 	%rd4, %SP, 24;
	or.b64  	%rd5, %rd4, 4;
	mov.u32 	%r1, 0;
	st.u32 	[%rd5], %r1;
	st.u64 	[%SP+32], %rd3;
	st.u32 	[%SP+24], %r1;
	bra.uni 	$L__BB12_1;
$L__BB12_1:
	ld.u64 	%rd6, [%SP+0];
	ld.u32 	%r2, [%rd6+8];
	ld.u64 	%rd7, [%rd6+16];
	ld.u32 	%r3, [%rd6+12];
	add.u64 	%rd8, %SP, 24;
	or.b64  	%rd9, %rd8, 4;
	st.u32 	[%rd9], %r3;
	st.u64 	[%SP+32], %rd7;
	st.u32 	[%SP+24], %r2;
	ld.u64 	%rd10, [%SP+32];
	st.u64 	[%SP+16], %rd10;
	ld.u64 	%rd11, [%SP+8];
	add.u64 	%rd12, %SP, 48;
	{ // callseq 31, 0
	.reg .b32 temp_param_reg;
	.param .b64 param0;
	st.param.b64 	[param0+0], %rd11;
	.param .b64 param1;
	st.param.b64 	[param1+0], %rd12;
	call.uni 
	_local__makeIndexTuple_chpl, 
	(
	param0, 
	param1
	);
	} // callseq 31
	ld.u64 	%rd13, [%SP+48];
	st.u64 	[%SP+40], %rd13;
	ld.u64 	%rd14, [%SP+16];
	add.u64 	%rd15, %SP, 40;
	{ // callseq 32, 0
	.reg .b32 temp_param_reg;
	.param .b64 param0;
	st.param.b64 	[param0+0], %rd14;
	.param .b64 param1;
	st.param.b64 	[param1+0], %rd15;
	.param .b32 retval0;
	call.uni (retval0), 
	_local_dsiMember_chpl, 
	(
	param0, 
	param1
	);
	ld.param.b32 	%r4, [retval0+0];
	} // callseq 32
	st.u8 	[%SP+56], %r4;
	ld.u8 	%rs1, [%SP+56];
	setp.ne.s16 	%p1, %rs1, 0;
	selp.u32 	%r6, 1, 0, %p1;
	st.param.b32 	[func_retval0+0], %r6;
	ret;

}
	// .globl	contains_chpl
.visible .func  (.param .b32 func_retval0) contains_chpl(
	.param .b64 contains_chpl_param_0,
	.param .b64 contains_chpl_param_1
)
{
	.local .align 8 .b8 	__local_depot13[64];
	.reg .b64 	%SP;
	.reg .b64 	%SPL;
	.reg .pred 	%p<2>;
	.reg .b16 	%rs<2>;
	.reg .b32 	%r<7>;
	.reg .b64 	%rd<16>;

	mov.u64 	%SPL, __local_depot13;
	cvta.local.u64 	%SP, %SPL;
	ld.param.u64 	%rd2, [contains_chpl_param_1];
	ld.param.u64 	%rd1, [contains_chpl_param_0];
	st.u64 	[%SP+0], %rd1;
	st.u64 	[%SP+8], %rd2;
	mov.u64 	%rd3, 0;
	st.u64 	[%SP+16], %rd3;
	add.u64 	%rd4, %SP, 24;
	or.b64  	%rd5, %rd4, 4;
	mov.u32 	%r1, 0;
	st.u32 	[%rd5], %r1;
	st.u64 	[%SP+32], %rd3;
	st.u32 	[%SP+24], %r1;
	bra.uni 	$L__BB13_1;
$L__BB13_1:
	ld.u64 	%rd6, [%SP+0];
	ld.u32 	%r2, [%rd6+8];
	ld.u64 	%rd7, [%rd6+16];
	ld.u32 	%r3, [%rd6+12];
	add.u64 	%rd8, %SP, 24;
	or.b64  	%rd9, %rd8, 4;
	st.u32 	[%rd9], %r3;
	st.u64 	[%SP+32], %rd7;
	st.u32 	[%SP+24], %r2;
	ld.u64 	%rd10, [%SP+32];
	st.u64 	[%SP+16], %rd10;
	ld.u64 	%rd11, [%SP+8];
	add.u64 	%rd12, %SP, 48;
	{ // callseq 33, 0
	.reg .b32 temp_param_reg;
	.param .b64 param0;
	st.param.b64 	[param0+0], %rd11;
	.param .b64 param1;
	st.param.b64 	[param1+0], %rd12;
	call.uni 
	_makeIndexTuple_chpl, 
	(
	param0, 
	param1
	);
	} // callseq 33
	ld.u64 	%rd13, [%SP+48];
	st.u64 	[%SP+40], %rd13;
	ld.u64 	%rd14, [%SP+16];
	add.u64 	%rd15, %SP, 40;
	{ // callseq 34, 0
	.reg .b32 temp_param_reg;
	.param .b64 param0;
	st.param.b64 	[param0+0], %rd14;
	.param .b64 param1;
	st.param.b64 	[param1+0], %rd15;
	.param .b32 retval0;
	call.uni (retval0), 
	dsiMember_chpl, 
	(
	param0, 
	param1
	);
	ld.param.b32 	%r4, [retval0+0];
	} // callseq 34
	st.u8 	[%SP+56], %r4;
	ld.u8 	%rs1, [%SP+56];
	setp.ne.s16 	%p1, %rs1, 0;
	selp.u32 	%r6, 1, 0, %p1;
	st.param.b32 	[func_retval0+0], %r6;
	ret;

}
	// .globl	_local_deinit_chpl
.visible .func _local_deinit_chpl(
	.param .align 8 .b8 _local_deinit_chpl_param_0[16]
)
{
	.local .align 8 .b8 	__local_depot14[16];
	.reg .b64 	%SP;
	.reg .b64 	%SPL;
	.reg .b32 	%r<3>;
	.reg .b64 	%rd<4>;

	mov.u64 	%SPL, __local_depot14;
	cvta.local.u64 	%SP, %SPL;
	ld.param.u64 	%rd1, [_local_deinit_chpl_param_0+8];
	ld.param.v2.u32 	{%r1, %r2}, [_local_deinit_chpl_param_0];
	add.u64 	%rd2, %SP, 0;
	or.b64  	%rd3, %rd2, 4;
	st.u32 	[%rd3], %r2;
	st.u64 	[%SP+8], %rd1;
	st.u32 	[%SP+0], %r1;
	bra.uni 	$L__BB14_1;
$L__BB14_1:
	ret;

}
	// .globl	deinit_chpl22
.visible .func deinit_chpl22(
	.param .align 8 .b8 deinit_chpl22_param_0[16]
)
{
	.local .align 8 .b8 	__local_depot15[16];
	.reg .b64 	%SP;
	.reg .b64 	%SPL;
	.reg .b32 	%r<3>;
	.reg .b64 	%rd<4>;

	mov.u64 	%SPL, __local_depot15;
	cvta.local.u64 	%SP, %SPL;
	ld.param.u64 	%rd1, [deinit_chpl22_param_0+8];
	ld.param.v2.u32 	{%r1, %r2}, [deinit_chpl22_param_0];
	add.u64 	%rd2, %SP, 0;
	or.b64  	%rd3, %rd2, 4;
	st.u32 	[%rd3], %r2;
	st.u64 	[%SP+8], %rd1;
	st.u32 	[%SP+0], %r1;
	bra.uni 	$L__BB15_1;
$L__BB15_1:
	ret;

}
	// .globl	_local_dsiMember_chpl
.visible .func  (.param .b32 func_retval0) _local_dsiMember_chpl(
	.param .b64 _local_dsiMember_chpl_param_0,
	.param .b64 _local_dsiMember_chpl_param_1
)
{
	.local .align 8 .b8 	__local_depot16[64];
	.reg .b64 	%SP;
	.reg .b64 	%SPL;
	.reg .pred 	%p<5>;
	.reg .b16 	%rs<8>;
	.reg .b32 	%r<2>;
	.reg .b64 	%rd<15>;

	mov.u64 	%SPL, __local_depot16;
	cvta.local.u64 	%SP, %SPL;
	ld.param.u64 	%rd2, [_local_dsiMember_chpl_param_1];
	ld.param.u64 	%rd1, [_local_dsiMember_chpl_param_0];
	st.u64 	[%SP+0], %rd1;
	st.u64 	[%SP+8], %rd2;
	mov.u64 	%rd3, 0;
	st.u64 	[%SP+24], %rd3;
	bra.uni 	$L__BB16_1;
$L__BB16_1:
	ld.u64 	%rd4, [%SP+0];
	add.s64 	%rd5, %rd4, 72;
	st.u64 	[%SP+24], %rd5;
	ld.u64 	%rd6, [%SP+24];
	ld.u64 	%rd7, [%rd6];
	ld.u64 	%rd8, [%rd6+8];
	st.u64 	[%SP+40], %rd8;
	st.u64 	[%SP+32], %rd7;
	ld.u64 	%rd9, [%SP+8];
	ld.u64 	%rd10, [%rd9];
	st.u64 	[%SP+48], %rd10;
	bra.uni 	$L__BB16_2;
$L__BB16_2:
	ld.u64 	%rd11, [%SP+48];
	ld.u64 	%rd12, [%SP+40];
	setp.le.s64 	%p1, %rd11, %rd12;
	@%p1 bra 	$L__BB16_5;
	bra.uni 	$L__BB16_3;
$L__BB16_3:
	bra.uni 	$L__BB16_4;
$L__BB16_4:
	mov.u16 	%rs3, 0;
	st.u8 	[%SP+56], %rs3;
	bra.uni 	$L__BB16_10;
$L__BB16_5:
	bra.uni 	$L__BB16_6;
$L__BB16_6:
	ld.u64 	%rd13, [%SP+48];
	ld.u64 	%rd14, [%SP+32];
	setp.ge.s64 	%p2, %rd13, %rd14;
	@%p2 bra 	$L__BB16_9;
	bra.uni 	$L__BB16_7;
$L__BB16_7:
	bra.uni 	$L__BB16_8;
$L__BB16_8:
	mov.u16 	%rs2, 0;
	st.u8 	[%SP+56], %rs2;
	bra.uni 	$L__BB16_10;
$L__BB16_9:
	mov.u16 	%rs1, 1;
	st.u8 	[%SP+56], %rs1;
	bra.uni 	$L__BB16_10;
$L__BB16_10:
	bra.uni 	$L__BB16_11;
$L__BB16_11:
	ld.u8 	%rs4, [%SP+56];
	setp.ne.s16 	%p3, %rs4, 0;
	@%p3 bra 	$L__BB16_14;
	bra.uni 	$L__BB16_12;
$L__BB16_12:
	bra.uni 	$L__BB16_13;
$L__BB16_13:
	mov.u16 	%rs6, 0;
	st.u8 	[%SP+16], %rs6;
	bra.uni 	$L__BB16_15;
$L__BB16_14:
	mov.u16 	%rs5, 1;
	st.u8 	[%SP+16], %rs5;
	bra.uni 	$L__BB16_15;
$L__BB16_15:
	ld.u8 	%rs7, [%SP+16];
	setp.ne.s16 	%p4, %rs7, 0;
	selp.u32 	%r1, 1, 0, %p4;
	st.param.b32 	[func_retval0+0], %r1;
	ret;

}
	// .globl	dsiMember_chpl
.visible .func  (.param .b32 func_retval0) dsiMember_chpl(
	.param .b64 dsiMember_chpl_param_0,
	.param .b64 dsiMember_chpl_param_1
)
{
	.local .align 8 .b8 	__local_depot17[64];
	.reg .b64 	%SP;
	.reg .b64 	%SPL;
	.reg .pred 	%p<5>;
	.reg .b16 	%rs<8>;
	.reg .b32 	%r<2>;
	.reg .b64 	%rd<15>;

	mov.u64 	%SPL, __local_depot17;
	cvta.local.u64 	%SP, %SPL;
	ld.param.u64 	%rd2, [dsiMember_chpl_param_1];
	ld.param.u64 	%rd1, [dsiMember_chpl_param_0];
	st.u64 	[%SP+0], %rd1;
	st.u64 	[%SP+8], %rd2;
	mov.u64 	%rd3, 0;
	st.u64 	[%SP+24], %rd3;
	bra.uni 	$L__BB17_1;
$L__BB17_1:
	ld.u64 	%rd4, [%SP+0];
	add.s64 	%rd5, %rd4, 72;
	st.u64 	[%SP+24], %rd5;
	ld.u64 	%rd6, [%SP+24];
	ld.u64 	%rd7, [%rd6];
	ld.u64 	%rd8, [%rd6+8];
	st.u64 	[%SP+40], %rd8;
	st.u64 	[%SP+32], %rd7;
	ld.u64 	%rd9, [%SP+8];
	ld.u64 	%rd10, [%rd9];
	st.u64 	[%SP+48], %rd10;
	bra.uni 	$L__BB17_2;
$L__BB17_2:
	ld.u64 	%rd11, [%SP+48];
	ld.u64 	%rd12, [%SP+40];
	setp.le.s64 	%p1, %rd11, %rd12;
	@%p1 bra 	$L__BB17_5;
	bra.uni 	$L__BB17_3;
$L__BB17_3:
	bra.uni 	$L__BB17_4;
$L__BB17_4:
	mov.u16 	%rs3, 0;
	st.u8 	[%SP+56], %rs3;
	bra.uni 	$L__BB17_10;
$L__BB17_5:
	bra.uni 	$L__BB17_6;
$L__BB17_6:
	ld.u64 	%rd13, [%SP+48];
	ld.u64 	%rd14, [%SP+32];
	setp.ge.s64 	%p2, %rd13, %rd14;
	@%p2 bra 	$L__BB17_9;
	bra.uni 	$L__BB17_7;
$L__BB17_7:
	bra.uni 	$L__BB17_8;
$L__BB17_8:
	mov.u16 	%rs2, 0;
	st.u8 	[%SP+56], %rs2;
	bra.uni 	$L__BB17_10;
$L__BB17_9:
	mov.u16 	%rs1, 1;
	st.u8 	[%SP+56], %rs1;
	bra.uni 	$L__BB17_10;
$L__BB17_10:
	bra.uni 	$L__BB17_11;
$L__BB17_11:
	ld.u8 	%rs4, [%SP+56];
	setp.ne.s16 	%p3, %rs4, 0;
	@%p3 bra 	$L__BB17_14;
	bra.uni 	$L__BB17_12;
$L__BB17_12:
	bra.uni 	$L__BB17_13;
$L__BB17_13:
	mov.u16 	%rs6, 0;
	st.u8 	[%SP+16], %rs6;
	bra.uni 	$L__BB17_15;
$L__BB17_14:
	mov.u16 	%rs5, 1;
	st.u8 	[%SP+16], %rs5;
	bra.uni 	$L__BB17_15;
$L__BB17_15:
	ld.u8 	%rs7, [%SP+16];
	setp.ne.s16 	%p4, %rs7, 0;
	selp.u32 	%r1, 1, 0, %p4;
	st.param.b32 	[func_retval0+0], %r1;
	ret;

}
	// .globl	chpl_gpu_kernel_DefaultRectangular_line_1166_
.visible .entry chpl_gpu_kernel_DefaultRectangular_line_1166_(
	.param .u64 chpl_gpu_kernel_DefaultRectangular_line_1166__param_0,
	.param .u64 chpl_gpu_kernel_DefaultRectangular_line_1166__param_1,
	.param .u64 chpl_gpu_kernel_DefaultRectangular_line_1166__param_2
)
{
	.local .align 8 .b8 	__local_depot18[88];
	.reg .b64 	%SP;
	.reg .b64 	%SPL;
	.reg .pred 	%p<2>;
	.reg .b32 	%r<16>;
	.reg .b64 	%rd<30>;

	mov.u64 	%SPL, __local_depot18;
	cvta.local.u64 	%SP, %SPL;
	ld.param.u64 	%rd3, [chpl_gpu_kernel_DefaultRectangular_line_1166__param_2];
	ld.param.u64 	%rd2, [chpl_gpu_kernel_DefaultRectangular_line_1166__param_1];
	ld.param.u64 	%rd1, [chpl_gpu_kernel_DefaultRectangular_line_1166__param_0];
	cvta.to.global.u64 	%rd4, %rd3;
	cvta.global.u64 	%rd5, %rd4;
	st.u64 	[%SP+0], %rd1;
	st.u64 	[%SP+8], %rd2;
	st.u64 	[%SP+16], %rd5;
	mov.u64 	%rd6, 0;
	st.u64 	[%SP+48], %rd6;
	add.u64 	%rd7, %SP, 56;
	or.b64  	%rd8, %rd7, 4;
	mov.u32 	%r1, 0;
	st.u32 	[%rd8], %r1;
	st.u64 	[%SP+64], %rd6;
	st.u32 	[%SP+56], %r1;
	bra.uni 	$L__BB18_1;
$L__BB18_1:
	{ // callseq 35, 0
	.reg .b32 temp_param_reg;
	.param .b32 retval0;
	call.uni (retval0), 
	_ZL21chpl_gpu_getBlockIdxXv, 
	(
	);
	ld.param.b32 	%r2, [retval0+0];
	} // callseq 35
	cvt.s64.s32 	%rd9, %r2;
	st.u64 	[%SP+24], %rd9;
	{ // callseq 36, 0
	.reg .b32 temp_param_reg;
	.param .b32 retval0;
	call.uni (retval0), 
	_ZL21chpl_gpu_getBlockDimXv, 
	(
	);
	ld.param.b32 	%r4, [retval0+0];
	} // callseq 36
	st.u32 	[%SP+32], %r4;
	{ // callseq 37, 0
	.reg .b32 temp_param_reg;
	.param .b32 retval0;
	call.uni (retval0), 
	_ZL22chpl_gpu_getThreadIdxXv, 
	(
	);
	ld.param.b32 	%r6, [retval0+0];
	} // callseq 37
	st.u32 	[%SP+36], %r6;
	ld.u64 	%rd10, [%SP+24];
	ld.s32 	%rd11, [%SP+32];
	mul.lo.s64 	%rd12, %rd10, %rd11;
	ld.s32 	%rd13, [%SP+36];
	add.s64 	%rd14, %rd12, %rd13;
	ld.u64 	%rd15, [%SP+0];
	add.s64 	%rd16, %rd14, %rd15;
	st.u64 	[%SP+40], %rd16;
	bra.uni 	$L__BB18_2;
$L__BB18_2:
	ld.u64 	%rd17, [%SP+40];
	ld.u64 	%rd18, [%SP+8];
	setp.le.s64 	%p1, %rd17, %rd18;
	@%p1 bra 	$L__BB18_5;
	bra.uni 	$L__BB18_3;
$L__BB18_3:
	bra.uni 	$L__BB18_4;
$L__BB18_4:
	bra.uni 	$L__BB18_6;
$L__BB18_5:
	ld.u64 	%rd19, [%SP+40];
	ld.u64 	%rd20, [%SP+16];
	shl.b64 	%rd21, %rd19, 4;
	add.s64 	%rd22, %rd20, %rd21;
	st.u64 	[%SP+48], %rd22;
	{ // callseq 38, 0
	.reg .b32 temp_param_reg;
	.param .align 16 .b8 retval0[8];
	call.uni (retval0), 
	_ZL20chpl_gen_getLocaleIDv, 
	(
	);
	ld.param.v2.b32 	{%r8, %r9}, [retval0+0];
	} // callseq 38
	ld.u64 	%rd23, [%SP+48];
	st.u64 	[%SP+80], %rd23;
	add.u64 	%rd24, %SP, 72;
	or.b64  	%rd25, %rd24, 4;
	st.u32 	[%rd25], %r9;
	st.u32 	[%SP+72], %r8;
	ld.u32 	%r12, [%rd25];
	ld.u32 	%r13, [%SP+72];
	ld.u64 	%rd26, [%SP+80];
	add.u64 	%rd27, %SP, 56;
	or.b64  	%rd28, %rd27, 4;
	st.u32 	[%rd28], %r12;
	st.u64 	[%SP+64], %rd26;
	st.u32 	[%SP+56], %r13;
	ld.u32 	%r14, [%rd28];
	ld.u64 	%rd29, [%SP+64];
	ld.u32 	%r15, [%SP+56];
	{ // callseq 39, 0
	.reg .b32 temp_param_reg;
	.param .align 8 .b8 param0[16];
	st.param.v2.b32 	[param0+0], {%r15, %r14};
	st.param.b64 	[param0+8], %rd29;
	call.uni 
	_local_deinit_chpl, 
	(
	param0
	);
	} // callseq 39
	bra.uni 	$L__BB18_6;
$L__BB18_6:
	ret;

}
	// .globl	chpl_gpu_kernel_DefaultRectangular_line_1536_
.visible .entry chpl_gpu_kernel_DefaultRectangular_line_1536_(
	.param .u64 chpl_gpu_kernel_DefaultRectangular_line_1536__param_0,
	.param .u64 chpl_gpu_kernel_DefaultRectangular_line_1536__param_1,
	.param .u64 chpl_gpu_kernel_DefaultRectangular_line_1536__param_2,
	.param .u64 chpl_gpu_kernel_DefaultRectangular_line_1536__param_3
)
{
	.local .align 8 .b8 	__local_depot19[88];
	.reg .b64 	%SP;
	.reg .b64 	%SPL;
	.reg .pred 	%p<2>;
	.reg .b32 	%r<9>;
	.reg .b64 	%rd<32>;

	mov.u64 	%SPL, __local_depot19;
	cvta.local.u64 	%SP, %SPL;
	ld.param.u64 	%rd4, [chpl_gpu_kernel_DefaultRectangular_line_1536__param_3];
	ld.param.u64 	%rd3, [chpl_gpu_kernel_DefaultRectangular_line_1536__param_2];
	ld.param.u64 	%rd2, [chpl_gpu_kernel_DefaultRectangular_line_1536__param_1];
	ld.param.u64 	%rd1, [chpl_gpu_kernel_DefaultRectangular_line_1536__param_0];
	cvta.to.global.u64 	%rd5, %rd4;
	cvta.global.u64 	%rd6, %rd5;
	cvta.to.global.u64 	%rd7, %rd3;
	cvta.global.u64 	%rd8, %rd7;
	st.u64 	[%SP+0], %rd1;
	st.u64 	[%SP+8], %rd2;
	st.u64 	[%SP+16], %rd8;
	st.u64 	[%SP+24], %rd6;
	mov.u64 	%rd9, 0;
	st.u64 	[%SP+56], %rd9;
	st.u64 	[%SP+64], %rd9;
	st.u64 	[%SP+72], %rd9;
	bra.uni 	$L__BB19_1;
$L__BB19_1:
	{ // callseq 40, 0
	.reg .b32 temp_param_reg;
	.param .b32 retval0;
	call.uni (retval0), 
	_ZL21chpl_gpu_getBlockIdxXv, 
	(
	);
	ld.param.b32 	%r1, [retval0+0];
	} // callseq 40
	cvt.s64.s32 	%rd10, %r1;
	st.u64 	[%SP+32], %rd10;
	{ // callseq 41, 0
	.reg .b32 temp_param_reg;
	.param .b32 retval0;
	call.uni (retval0), 
	_ZL21chpl_gpu_getBlockDimXv, 
	(
	);
	ld.param.b32 	%r3, [retval0+0];
	} // callseq 41
	st.u32 	[%SP+40], %r3;
	{ // callseq 42, 0
	.reg .b32 temp_param_reg;
	.param .b32 retval0;
	call.uni (retval0), 
	_ZL22chpl_gpu_getThreadIdxXv, 
	(
	);
	ld.param.b32 	%r5, [retval0+0];
	} // callseq 42
	st.u32 	[%SP+44], %r5;
	ld.u64 	%rd11, [%SP+32];
	ld.s32 	%rd12, [%SP+40];
	mul.lo.s64 	%rd13, %rd11, %rd12;
	ld.s32 	%rd14, [%SP+44];
	add.s64 	%rd15, %rd13, %rd14;
	ld.u64 	%rd16, [%SP+0];
	add.s64 	%rd17, %rd15, %rd16;
	st.u64 	[%SP+48], %rd17;
	bra.uni 	$L__BB19_2;
$L__BB19_2:
	ld.u64 	%rd18, [%SP+48];
	ld.u64 	%rd19, [%SP+8];
	setp.le.s64 	%p1, %rd18, %rd19;
	@%p1 bra 	$L__BB19_5;
	bra.uni 	$L__BB19_3;
$L__BB19_3:
	bra.uni 	$L__BB19_4;
$L__BB19_4:
	bra.uni 	$L__BB19_6;
$L__BB19_5:
	ld.u64 	%rd20, [%SP+48];
	ld.u64 	%rd21, [%SP+16];
	shl.b64 	%rd22, %rd20, 4;
	add.s64 	%rd23, %rd21, %rd22;
	st.u64 	[%SP+64], %rd23;
	ld.u64 	%rd24, [%SP+64];
	st.u64 	[%SP+56], %rd24;
	ld.u64 	%rd25, [%SP+48];
	ld.u64 	%rd26, [%SP+24];
	shl.b64 	%rd27, %rd25, 4;
	add.s64 	%rd28, %rd26, %rd27;
	st.u64 	[%SP+72], %rd28;
	ld.u64 	%rd29, [%SP+56];
	ld.u64 	%rd30, [%SP+72];
	ld.u32 	%r7, [%rd30];
	ld.u32 	%r8, [%rd30+4];
	ld.u64 	%rd31, [%rd30+8];
	st.u64 	[%rd29+8], %rd31;
	st.u32 	[%rd29+4], %r8;
	st.u32 	[%rd29], %r7;
	bra.uni 	$L__BB19_6;
$L__BB19_6:
	ret;

}
	// .globl	chpl_gpu_kernel_DefaultRectangular_line_1536_2
.visible .entry chpl_gpu_kernel_DefaultRectangular_line_1536_2(
	.param .u64 chpl_gpu_kernel_DefaultRectangular_line_1536_2_param_0,
	.param .u64 chpl_gpu_kernel_DefaultRectangular_line_1536_2_param_1,
	.param .u64 chpl_gpu_kernel_DefaultRectangular_line_1536_2_param_2,
	.param .u64 chpl_gpu_kernel_DefaultRectangular_line_1536_2_param_3
)
{
	.local .align 8 .b8 	__local_depot20[88];
	.reg .b64 	%SP;
	.reg .b64 	%SPL;
	.reg .pred 	%p<2>;
	.reg .b32 	%r<9>;
	.reg .b64 	%rd<32>;

	mov.u64 	%SPL, __local_depot20;
	cvta.local.u64 	%SP, %SPL;
	ld.param.u64 	%rd4, [chpl_gpu_kernel_DefaultRectangular_line_1536_2_param_3];
	ld.param.u64 	%rd3, [chpl_gpu_kernel_DefaultRectangular_line_1536_2_param_2];
	ld.param.u64 	%rd2, [chpl_gpu_kernel_DefaultRectangular_line_1536_2_param_1];
	ld.param.u64 	%rd1, [chpl_gpu_kernel_DefaultRectangular_line_1536_2_param_0];
	cvta.to.global.u64 	%rd5, %rd4;
	cvta.global.u64 	%rd6, %rd5;
	cvta.to.global.u64 	%rd7, %rd3;
	cvta.global.u64 	%rd8, %rd7;
	st.u64 	[%SP+0], %rd1;
	st.u64 	[%SP+8], %rd2;
	st.u64 	[%SP+16], %rd8;
	st.u64 	[%SP+24], %rd6;
	mov.u64 	%rd9, 0;
	st.u64 	[%SP+56], %rd9;
	st.u64 	[%SP+64], %rd9;
	st.u64 	[%SP+72], %rd9;
	bra.uni 	$L__BB20_1;
$L__BB20_1:
	{ // callseq 43, 0
	.reg .b32 temp_param_reg;
	.param .b32 retval0;
	call.uni (retval0), 
	_ZL21chpl_gpu_getBlockIdxXv, 
	(
	);
	ld.param.b32 	%r1, [retval0+0];
	} // callseq 43
	cvt.s64.s32 	%rd10, %r1;
	st.u64 	[%SP+32], %rd10;
	{ // callseq 44, 0
	.reg .b32 temp_param_reg;
	.param .b32 retval0;
	call.uni (retval0), 
	_ZL21chpl_gpu_getBlockDimXv, 
	(
	);
	ld.param.b32 	%r3, [retval0+0];
	} // callseq 44
	st.u32 	[%SP+40], %r3;
	{ // callseq 45, 0
	.reg .b32 temp_param_reg;
	.param .b32 retval0;
	call.uni (retval0), 
	_ZL22chpl_gpu_getThreadIdxXv, 
	(
	);
	ld.param.b32 	%r5, [retval0+0];
	} // callseq 45
	st.u32 	[%SP+44], %r5;
	ld.u64 	%rd11, [%SP+32];
	ld.s32 	%rd12, [%SP+40];
	mul.lo.s64 	%rd13, %rd11, %rd12;
	ld.s32 	%rd14, [%SP+44];
	add.s64 	%rd15, %rd13, %rd14;
	ld.u64 	%rd16, [%SP+0];
	add.s64 	%rd17, %rd15, %rd16;
	st.u64 	[%SP+48], %rd17;
	bra.uni 	$L__BB20_2;
$L__BB20_2:
	ld.u64 	%rd18, [%SP+48];
	ld.u64 	%rd19, [%SP+8];
	setp.le.s64 	%p1, %rd18, %rd19;
	@%p1 bra 	$L__BB20_5;
	bra.uni 	$L__BB20_3;
$L__BB20_3:
	bra.uni 	$L__BB20_4;
$L__BB20_4:
	bra.uni 	$L__BB20_6;
$L__BB20_5:
	ld.u64 	%rd20, [%SP+48];
	ld.u64 	%rd21, [%SP+16];
	shl.b64 	%rd22, %rd20, 4;
	add.s64 	%rd23, %rd21, %rd22;
	st.u64 	[%SP+64], %rd23;
	ld.u64 	%rd24, [%SP+64];
	st.u64 	[%SP+56], %rd24;
	ld.u64 	%rd25, [%SP+48];
	ld.u64 	%rd26, [%SP+24];
	shl.b64 	%rd27, %rd25, 4;
	add.s64 	%rd28, %rd26, %rd27;
	st.u64 	[%SP+72], %rd28;
	ld.u64 	%rd29, [%SP+56];
	ld.u64 	%rd30, [%SP+72];
	ld.u32 	%r7, [%rd30];
	ld.u32 	%r8, [%rd30+4];
	ld.u64 	%rd31, [%rd30+8];
	st.u64 	[%rd29+8], %rd31;
	st.u32 	[%rd29+4], %r8;
	st.u32 	[%rd29], %r7;
	bra.uni 	$L__BB20_6;
$L__BB20_6:
	ret;

}
	// .globl	chpl_gpu_kernel_DefaultRectangular_line_1536_3
.visible .entry chpl_gpu_kernel_DefaultRectangular_line_1536_3(
	.param .u64 chpl_gpu_kernel_DefaultRectangular_line_1536_3_param_0,
	.param .u64 chpl_gpu_kernel_DefaultRectangular_line_1536_3_param_1,
	.param .u64 chpl_gpu_kernel_DefaultRectangular_line_1536_3_param_2,
	.param .u64 chpl_gpu_kernel_DefaultRectangular_line_1536_3_param_3,
	.param .u64 chpl_gpu_kernel_DefaultRectangular_line_1536_3_param_4,
	.param .u64 chpl_gpu_kernel_DefaultRectangular_line_1536_3_param_5,
	.param .u64 chpl_gpu_kernel_DefaultRectangular_line_1536_3_param_6
)
{
	.local .align 8 .b8 	__local_depot21[248];
	.reg .b64 	%SP;
	.reg .b64 	%SPL;
	.reg .pred 	%p<2>;
	.reg .b32 	%r<7>;
	.reg .b64 	%rd<77>;
	.reg .f64 	%fd<2>;

	mov.u64 	%SPL, __local_depot21;
	cvta.local.u64 	%SP, %SPL;
	ld.param.u64 	%rd7, [chpl_gpu_kernel_DefaultRectangular_line_1536_3_param_6];
	ld.param.u64 	%rd6, [chpl_gpu_kernel_DefaultRectangular_line_1536_3_param_5];
	ld.param.u64 	%rd5, [chpl_gpu_kernel_DefaultRectangular_line_1536_3_param_4];
	ld.param.u64 	%rd4, [chpl_gpu_kernel_DefaultRectangular_line_1536_3_param_3];
	ld.param.u64 	%rd3, [chpl_gpu_kernel_DefaultRectangular_line_1536_3_param_2];
	ld.param.u64 	%rd2, [chpl_gpu_kernel_DefaultRectangular_line_1536_3_param_1];
	ld.param.u64 	%rd1, [chpl_gpu_kernel_DefaultRectangular_line_1536_3_param_0];
	cvta.to.global.u64 	%rd8, %rd7;
	cvta.global.u64 	%rd9, %rd8;
	cvta.to.global.u64 	%rd10, %rd6;
	cvta.global.u64 	%rd11, %rd10;
	cvta.to.global.u64 	%rd12, %rd5;
	cvta.global.u64 	%rd13, %rd12;
	cvta.to.global.u64 	%rd14, %rd4;
	cvta.global.u64 	%rd15, %rd14;
	st.u64 	[%SP+0], %rd1;
	st.u64 	[%SP+8], %rd2;
	st.u64 	[%SP+16], %rd3;
	st.u64 	[%SP+24], %rd15;
	st.u64 	[%SP+32], %rd13;
	st.u64 	[%SP+40], %rd11;
	st.u64 	[%SP+48], %rd9;
	mov.u64 	%rd16, 0;
	st.u64 	[%SP+96], %rd16;
	st.u64 	[%SP+144], %rd16;
	st.u64 	[%SP+152], %rd16;
	st.u64 	[%SP+160], %rd16;
	st.u64 	[%SP+168], %rd16;
	st.u64 	[%SP+216], %rd16;
	st.u64 	[%SP+224], %rd16;
	st.u64 	[%SP+232], %rd16;
	st.u64 	[%SP+240], %rd16;
	bra.uni 	$L__BB21_1;
$L__BB21_1:
	{ // callseq 46, 0
	.reg .b32 temp_param_reg;
	.param .b32 retval0;
	call.uni (retval0), 
	_ZL21chpl_gpu_getBlockIdxXv, 
	(
	);
	ld.param.b32 	%r1, [retval0+0];
	} // callseq 46
	cvt.s64.s32 	%rd17, %r1;
	st.u64 	[%SP+56], %rd17;
	{ // callseq 47, 0
	.reg .b32 temp_param_reg;
	.param .b32 retval0;
	call.uni (retval0), 
	_ZL21chpl_gpu_getBlockDimXv, 
	(
	);
	ld.param.b32 	%r3, [retval0+0];
	} // callseq 47
	st.u32 	[%SP+64], %r3;
	{ // callseq 48, 0
	.reg .b32 temp_param_reg;
	.param .b32 retval0;
	call.uni (retval0), 
	_ZL22chpl_gpu_getThreadIdxXv, 
	(
	);
	ld.param.b32 	%r5, [retval0+0];
	} // callseq 48
	st.u32 	[%SP+68], %r5;
	ld.u64 	%rd18, [%SP+56];
	ld.s32 	%rd19, [%SP+64];
	mul.lo.s64 	%rd20, %rd18, %rd19;
	ld.s32 	%rd21, [%SP+68];
	add.s64 	%rd22, %rd20, %rd21;
	ld.u64 	%rd23, [%SP+0];
	add.s64 	%rd24, %rd22, %rd23;
	st.u64 	[%SP+72], %rd24;
	bra.uni 	$L__BB21_2;
$L__BB21_2:
	ld.u64 	%rd25, [%SP+72];
	ld.u64 	%rd26, [%SP+8];
	setp.le.s64 	%p1, %rd25, %rd26;
	@%p1 bra 	$L__BB21_5;
	bra.uni 	$L__BB21_3;
$L__BB21_3:
	bra.uni 	$L__BB21_4;
$L__BB21_4:
	bra.uni 	$L__BB21_6;
$L__BB21_5:
	ld.u64 	%rd27, [%SP+16];
	st.u64 	[%SP+80], %rd27;
	ld.u64 	%rd28, [%SP+72];
	st.u64 	[%SP+88], %rd28;
	ld.u64 	%rd29, [%SP+80];
	st.u64 	[%SP+104], %rd29;
	ld.u64 	%rd30, [%SP+88];
	st.u64 	[%SP+112], %rd30;
	ld.u64 	%rd31, [%SP+112];
	st.u64 	[%SP+120], %rd31;
	mov.u64 	%rd32, 0;
	st.u64 	[%SP+136], %rd32;
	ld.u64 	%rd33, [%SP+24];
	add.s64 	%rd34, %rd33, 96;
	st.u64 	[%SP+144], %rd34;
	add.u64 	%rd35, %SP, 136;
	st.u64 	[%SP+152], %rd35;
	ld.u64 	%rd36, [%SP+144];
	ld.u64 	%rd37, [%SP+104];
	ld.u64 	%rd38, [%rd36];
	mul.lo.s64 	%rd39, %rd37, %rd38;
	ld.u64 	%rd40, [%SP+152];
	ld.u64 	%rd41, [%rd40];
	add.s64 	%rd42, %rd41, %rd39;
	st.u64 	[%rd40], %rd42;
	st.u64 	[%SP+160], %rd35;
	ld.u64 	%rd43, [%SP+160];
	ld.u64 	%rd44, [%SP+120];
	ld.u64 	%rd45, [%rd43];
	add.s64 	%rd46, %rd45, %rd44;
	st.u64 	[%rd43], %rd46;
	ld.u64 	%rd47, [%SP+136];
	st.u64 	[%SP+128], %rd47;
	ld.u64 	%rd48, [%SP+128];
	ld.u64 	%rd49, [%SP+32];
	shl.b64 	%rd50, %rd48, 3;
	add.s64 	%rd51, %rd49, %rd50;
	st.u64 	[%SP+168], %rd51;
	ld.u64 	%rd52, [%SP+168];
	st.u64 	[%SP+96], %rd52;
	ld.u64 	%rd53, [%SP+80];
	st.u64 	[%SP+176], %rd53;
	ld.u64 	%rd54, [%SP+88];
	st.u64 	[%SP+184], %rd54;
	ld.u64 	%rd55, [%SP+184];
	st.u64 	[%SP+192], %rd55;
	st.u64 	[%SP+208], %rd32;
	ld.u64 	%rd56, [%SP+40];
	add.s64 	%rd57, %rd56, 96;
	st.u64 	[%SP+216], %rd57;
	add.u64 	%rd58, %SP, 208;
	st.u64 	[%SP+224], %rd58;
	ld.u64 	%rd59, [%SP+216];
	ld.u64 	%rd60, [%SP+176];
	ld.u64 	%rd61, [%rd59];
	mul.lo.s64 	%rd62, %rd60, %rd61;
	ld.u64 	%rd63, [%SP+224];
	ld.u64 	%rd64, [%rd63];
	add.s64 	%rd65, %rd64, %rd62;
	st.u64 	[%rd63], %rd65;
	st.u64 	[%SP+232], %rd58;
	ld.u64 	%rd66, [%SP+232];
	ld.u64 	%rd67, [%SP+192];
	ld.u64 	%rd68, [%rd66];
	add.s64 	%rd69, %rd68, %rd67;
	st.u64 	[%rd66], %rd69;
	ld.u64 	%rd70, [%SP+208];
	st.u64 	[%SP+200], %rd70;
	ld.u64 	%rd71, [%SP+200];
	ld.u64 	%rd72, [%SP+48];
	shl.b64 	%rd73, %rd71, 3;
	add.s64 	%rd74, %rd72, %rd73;
	st.u64 	[%SP+240], %rd74;
	ld.u64 	%rd75, [%SP+96];
	ld.u64 	%rd76, [%SP+240];
	ld.f64 	%fd1, [%rd76];
	st.f64 	[%rd75], %fd1;
	bra.uni 	$L__BB21_6;
$L__BB21_6:
	ret;

}
	// .globl	chpl_gpu_kernel_DefaultRectangular_line_1536_4
.visible .entry chpl_gpu_kernel_DefaultRectangular_line_1536_4(
	.param .u64 chpl_gpu_kernel_DefaultRectangular_line_1536_4_param_0,
	.param .u64 chpl_gpu_kernel_DefaultRectangular_line_1536_4_param_1,
	.param .u64 chpl_gpu_kernel_DefaultRectangular_line_1536_4_param_2,
	.param .u64 chpl_gpu_kernel_DefaultRectangular_line_1536_4_param_3,
	.param .u64 chpl_gpu_kernel_DefaultRectangular_line_1536_4_param_4,
	.param .u64 chpl_gpu_kernel_DefaultRectangular_line_1536_4_param_5,
	.param .u64 chpl_gpu_kernel_DefaultRectangular_line_1536_4_param_6,
	.param .u64 chpl_gpu_kernel_DefaultRectangular_line_1536_4_param_7
)
{
	.local .align 8 .b8 	__local_depot22[272];
	.reg .b64 	%SP;
	.reg .b64 	%SPL;
	.reg .pred 	%p<4>;
	.reg .b32 	%r<7>;
	.reg .b64 	%rd<87>;
	.reg .f64 	%fd<2>;

	mov.u64 	%SPL, __local_depot22;
	cvta.local.u64 	%SP, %SPL;
	ld.param.u64 	%rd8, [chpl_gpu_kernel_DefaultRectangular_line_1536_4_param_7];
	ld.param.u64 	%rd7, [chpl_gpu_kernel_DefaultRectangular_line_1536_4_param_6];
	ld.param.u64 	%rd6, [chpl_gpu_kernel_DefaultRectangular_line_1536_4_param_5];
	ld.param.u64 	%rd5, [chpl_gpu_kernel_DefaultRectangular_line_1536_4_param_4];
	ld.param.u64 	%rd4, [chpl_gpu_kernel_DefaultRectangular_line_1536_4_param_3];
	ld.param.u64 	%rd3, [chpl_gpu_kernel_DefaultRectangular_line_1536_4_param_2];
	ld.param.u64 	%rd2, [chpl_gpu_kernel_DefaultRectangular_line_1536_4_param_1];
	ld.param.u64 	%rd1, [chpl_gpu_kernel_DefaultRectangular_line_1536_4_param_0];
	cvta.to.global.u64 	%rd9, %rd6;
	cvta.global.u64 	%rd10, %rd9;
	cvta.to.global.u64 	%rd11, %rd5;
	cvta.global.u64 	%rd12, %rd11;
	cvta.to.global.u64 	%rd13, %rd4;
	cvta.global.u64 	%rd14, %rd13;
	cvta.to.global.u64 	%rd15, %rd3;
	cvta.global.u64 	%rd16, %rd15;
	st.u64 	[%SP+0], %rd1;
	st.u64 	[%SP+8], %rd2;
	st.u64 	[%SP+16], %rd16;
	st.u64 	[%SP+24], %rd14;
	st.u64 	[%SP+32], %rd12;
	st.u64 	[%SP+40], %rd10;
	st.u64 	[%SP+48], %rd7;
	st.u64 	[%SP+56], %rd8;
	mov.u64 	%rd17, 0;
	st.u64 	[%SP+120], %rd17;
	st.u64 	[%SP+168], %rd17;
	st.u64 	[%SP+176], %rd17;
	st.u64 	[%SP+184], %rd17;
	st.u64 	[%SP+192], %rd17;
	st.u64 	[%SP+240], %rd17;
	st.u64 	[%SP+248], %rd17;
	st.u64 	[%SP+256], %rd17;
	st.u64 	[%SP+264], %rd17;
	bra.uni 	$L__BB22_1;
$L__BB22_1:
	{ // callseq 49, 0
	.reg .b32 temp_param_reg;
	.param .b32 retval0;
	call.uni (retval0), 
	_ZL21chpl_gpu_getBlockIdxXv, 
	(
	);
	ld.param.b32 	%r1, [retval0+0];
	} // callseq 49
	cvt.s64.s32 	%rd18, %r1;
	st.u64 	[%SP+64], %rd18;
	{ // callseq 50, 0
	.reg .b32 temp_param_reg;
	.param .b32 retval0;
	call.uni (retval0), 
	_ZL21chpl_gpu_getBlockDimXv, 
	(
	);
	ld.param.b32 	%r3, [retval0+0];
	} // callseq 50
	st.u32 	[%SP+72], %r3;
	{ // callseq 51, 0
	.reg .b32 temp_param_reg;
	.param .b32 retval0;
	call.uni (retval0), 
	_ZL22chpl_gpu_getThreadIdxXv, 
	(
	);
	ld.param.b32 	%r5, [retval0+0];
	} // callseq 51
	st.u32 	[%SP+76], %r5;
	ld.u64 	%rd19, [%SP+64];
	ld.s32 	%rd20, [%SP+72];
	mul.lo.s64 	%rd21, %rd19, %rd20;
	ld.s32 	%rd22, [%SP+76];
	add.s64 	%rd23, %rd21, %rd22;
	ld.u64 	%rd24, [%SP+0];
	add.s64 	%rd25, %rd23, %rd24;
	st.u64 	[%SP+80], %rd25;
	bra.uni 	$L__BB22_2;
$L__BB22_2:
	ld.u64 	%rd26, [%SP+80];
	ld.u64 	%rd27, [%SP+8];
	setp.le.s64 	%p1, %rd26, %rd27;
	@%p1 bra 	$L__BB22_5;
	bra.uni 	$L__BB22_3;
$L__BB22_3:
	bra.uni 	$L__BB22_4;
$L__BB22_4:
	bra.uni 	$L__BB22_9;
$L__BB22_5:
	ld.u64 	%rd28, [%SP+80];
	st.u64 	[%SP+88], %rd28;
	mov.u64 	%rd29, 0;
	st.u64 	[%SP+96], %rd29;
	bra.uni 	$L__BB22_6;
$L__BB22_6:
	ld.u64 	%rd30, [%SP+48];
	st.u64 	[%SP+96], %rd30;
	ld.u64 	%rd31, [%SP+96];
	ld.u64 	%rd32, [%SP+56];
	setp.gt.s64 	%p2, %rd31, %rd32;
	@%p2 bra 	$L__BB22_8;
	bra.uni 	$L__BB22_7;
$L__BB22_7:
	ld.u64 	%rd33, [%SP+88];
	st.u64 	[%SP+104], %rd33;
	ld.u64 	%rd34, [%SP+96];
	st.u64 	[%SP+112], %rd34;
	ld.u64 	%rd35, [%SP+104];
	st.u64 	[%SP+128], %rd35;
	ld.u64 	%rd36, [%SP+112];
	st.u64 	[%SP+136], %rd36;
	ld.u64 	%rd37, [%SP+136];
	st.u64 	[%SP+144], %rd37;
	mov.u64 	%rd38, 0;
	st.u64 	[%SP+160], %rd38;
	ld.u64 	%rd39, [%SP+16];
	add.s64 	%rd40, %rd39, 96;
	st.u64 	[%SP+168], %rd40;
	add.u64 	%rd41, %SP, 160;
	st.u64 	[%SP+176], %rd41;
	ld.u64 	%rd42, [%SP+168];
	ld.u64 	%rd43, [%SP+128];
	ld.u64 	%rd44, [%rd42];
	mul.lo.s64 	%rd45, %rd43, %rd44;
	ld.u64 	%rd46, [%SP+176];
	ld.u64 	%rd47, [%rd46];
	add.s64 	%rd48, %rd47, %rd45;
	st.u64 	[%rd46], %rd48;
	st.u64 	[%SP+184], %rd41;
	ld.u64 	%rd49, [%SP+184];
	ld.u64 	%rd50, [%SP+144];
	ld.u64 	%rd51, [%rd49];
	add.s64 	%rd52, %rd51, %rd50;
	st.u64 	[%rd49], %rd52;
	ld.u64 	%rd53, [%SP+160];
	st.u64 	[%SP+152], %rd53;
	ld.u64 	%rd54, [%SP+152];
	ld.u64 	%rd55, [%SP+24];
	shl.b64 	%rd56, %rd54, 3;
	add.s64 	%rd57, %rd55, %rd56;
	st.u64 	[%SP+192], %rd57;
	ld.u64 	%rd58, [%SP+192];
	st.u64 	[%SP+120], %rd58;
	ld.u64 	%rd59, [%SP+104];
	st.u64 	[%SP+200], %rd59;
	ld.u64 	%rd60, [%SP+112];
	st.u64 	[%SP+208], %rd60;
	ld.u64 	%rd61, [%SP+208];
	st.u64 	[%SP+216], %rd61;
	st.u64 	[%SP+232], %rd38;
	ld.u64 	%rd62, [%SP+32];
	add.s64 	%rd63, %rd62, 96;
	st.u64 	[%SP+240], %rd63;
	add.u64 	%rd64, %SP, 232;
	st.u64 	[%SP+248], %rd64;
	ld.u64 	%rd65, [%SP+240];
	ld.u64 	%rd66, [%SP+200];
	ld.u64 	%rd67, [%rd65];
	mul.lo.s64 	%rd68, %rd66, %rd67;
	ld.u64 	%rd69, [%SP+248];
	ld.u64 	%rd70, [%rd69];
	add.s64 	%rd71, %rd70, %rd68;
	st.u64 	[%rd69], %rd71;
	st.u64 	[%SP+256], %rd64;
	ld.u64 	%rd72, [%SP+256];
	ld.u64 	%rd73, [%SP+216];
	ld.u64 	%rd74, [%rd72];
	add.s64 	%rd75, %rd74, %rd73;
	st.u64 	[%rd72], %rd75;
	ld.u64 	%rd76, [%SP+232];
	st.u64 	[%SP+224], %rd76;
	ld.u64 	%rd77, [%SP+224];
	ld.u64 	%rd78, [%SP+40];
	shl.b64 	%rd79, %rd77, 3;
	add.s64 	%rd80, %rd78, %rd79;
	st.u64 	[%SP+264], %rd80;
	ld.u64 	%rd81, [%SP+120];
	ld.u64 	%rd82, [%SP+264];
	ld.f64 	%fd1, [%rd82];
	st.f64 	[%rd81], %fd1;
	ld.u64 	%rd83, [%SP+96];
	add.s64 	%rd84, %rd83, 1;
	st.u64 	[%SP+96], %rd84;
	ld.u64 	%rd85, [%SP+96];
	ld.u64 	%rd86, [%SP+56];
	setp.le.s64 	%p3, %rd85, %rd86;
	@%p3 bra 	$L__BB22_7;
	bra.uni 	$L__BB22_8;
$L__BB22_8:
	bra.uni 	$L__BB22_9;
$L__BB22_9:
	ret;

}
	// .globl	chpl_gpu_kernel_DefaultRectangular_line_1536_5
.visible .entry chpl_gpu_kernel_DefaultRectangular_line_1536_5(
	.param .u64 chpl_gpu_kernel_DefaultRectangular_line_1536_5_param_0,
	.param .u64 chpl_gpu_kernel_DefaultRectangular_line_1536_5_param_1,
	.param .u64 chpl_gpu_kernel_DefaultRectangular_line_1536_5_param_2,
	.param .u64 chpl_gpu_kernel_DefaultRectangular_line_1536_5_param_3
)
{
	.local .align 8 .b8 	__local_depot23[88];
	.reg .b64 	%SP;
	.reg .b64 	%SPL;
	.reg .pred 	%p<2>;
	.reg .b32 	%r<7>;
	.reg .b64 	%rd<32>;

	mov.u64 	%SPL, __local_depot23;
	cvta.local.u64 	%SP, %SPL;
	ld.param.u64 	%rd4, [chpl_gpu_kernel_DefaultRectangular_line_1536_5_param_3];
	ld.param.u64 	%rd3, [chpl_gpu_kernel_DefaultRectangular_line_1536_5_param_2];
	ld.param.u64 	%rd2, [chpl_gpu_kernel_DefaultRectangular_line_1536_5_param_1];
	ld.param.u64 	%rd1, [chpl_gpu_kernel_DefaultRectangular_line_1536_5_param_0];
	cvta.to.global.u64 	%rd5, %rd4;
	cvta.global.u64 	%rd6, %rd5;
	cvta.to.global.u64 	%rd7, %rd3;
	cvta.global.u64 	%rd8, %rd7;
	st.u64 	[%SP+0], %rd1;
	st.u64 	[%SP+8], %rd2;
	st.u64 	[%SP+16], %rd8;
	st.u64 	[%SP+24], %rd6;
	mov.u64 	%rd9, 0;
	st.u64 	[%SP+56], %rd9;
	st.u64 	[%SP+64], %rd9;
	st.u64 	[%SP+72], %rd9;
	bra.uni 	$L__BB23_1;
$L__BB23_1:
	{ // callseq 52, 0
	.reg .b32 temp_param_reg;
	.param .b32 retval0;
	call.uni (retval0), 
	_ZL21chpl_gpu_getBlockIdxXv, 
	(
	);
	ld.param.b32 	%r1, [retval0+0];
	} // callseq 52
	cvt.s64.s32 	%rd10, %r1;
	st.u64 	[%SP+32], %rd10;
	{ // callseq 53, 0
	.reg .b32 temp_param_reg;
	.param .b32 retval0;
	call.uni (retval0), 
	_ZL21chpl_gpu_getBlockDimXv, 
	(
	);
	ld.param.b32 	%r3, [retval0+0];
	} // callseq 53
	st.u32 	[%SP+40], %r3;
	{ // callseq 54, 0
	.reg .b32 temp_param_reg;
	.param .b32 retval0;
	call.uni (retval0), 
	_ZL22chpl_gpu_getThreadIdxXv, 
	(
	);
	ld.param.b32 	%r5, [retval0+0];
	} // callseq 54
	st.u32 	[%SP+44], %r5;
	ld.u64 	%rd11, [%SP+32];
	ld.s32 	%rd12, [%SP+40];
	mul.lo.s64 	%rd13, %rd11, %rd12;
	ld.s32 	%rd14, [%SP+44];
	add.s64 	%rd15, %rd13, %rd14;
	ld.u64 	%rd16, [%SP+0];
	add.s64 	%rd17, %rd15, %rd16;
	st.u64 	[%SP+48], %rd17;
	bra.uni 	$L__BB23_2;
$L__BB23_2:
	ld.u64 	%rd18, [%SP+48];
	ld.u64 	%rd19, [%SP+8];
	setp.le.s64 	%p1, %rd18, %rd19;
	@%p1 bra 	$L__BB23_5;
	bra.uni 	$L__BB23_3;
$L__BB23_3:
	bra.uni 	$L__BB23_4;
$L__BB23_4:
	bra.uni 	$L__BB23_6;
$L__BB23_5:
	ld.u64 	%rd20, [%SP+48];
	ld.u64 	%rd21, [%SP+16];
	shl.b64 	%rd22, %rd20, 3;
	add.s64 	%rd23, %rd21, %rd22;
	st.u64 	[%SP+64], %rd23;
	ld.u64 	%rd24, [%SP+64];
	st.u64 	[%SP+56], %rd24;
	ld.u64 	%rd25, [%SP+48];
	ld.u64 	%rd26, [%SP+24];
	shl.b64 	%rd27, %rd25, 3;
	add.s64 	%rd28, %rd26, %rd27;
	st.u64 	[%SP+72], %rd28;
	ld.u64 	%rd29, [%SP+56];
	ld.u64 	%rd30, [%SP+72];
	ld.u64 	%rd31, [%rd30];
	st.u64 	[%rd29], %rd31;
	bra.uni 	$L__BB23_6;
$L__BB23_6:
	ret;

}
	// .globl	chpl_gpu_kernel_DefaultRectangular_line_1536_6
.visible .entry chpl_gpu_kernel_DefaultRectangular_line_1536_6(
	.param .u64 chpl_gpu_kernel_DefaultRectangular_line_1536_6_param_0,
	.param .u64 chpl_gpu_kernel_DefaultRectangular_line_1536_6_param_1,
	.param .u64 chpl_gpu_kernel_DefaultRectangular_line_1536_6_param_2,
	.param .u64 chpl_gpu_kernel_DefaultRectangular_line_1536_6_param_3
)
{
	.local .align 8 .b8 	__local_depot24[88];
	.reg .b64 	%SP;
	.reg .b64 	%SPL;
	.reg .pred 	%p<2>;
	.reg .b32 	%r<7>;
	.reg .b64 	%rd<32>;

	mov.u64 	%SPL, __local_depot24;
	cvta.local.u64 	%SP, %SPL;
	ld.param.u64 	%rd4, [chpl_gpu_kernel_DefaultRectangular_line_1536_6_param_3];
	ld.param.u64 	%rd3, [chpl_gpu_kernel_DefaultRectangular_line_1536_6_param_2];
	ld.param.u64 	%rd2, [chpl_gpu_kernel_DefaultRectangular_line_1536_6_param_1];
	ld.param.u64 	%rd1, [chpl_gpu_kernel_DefaultRectangular_line_1536_6_param_0];
	cvta.to.global.u64 	%rd5, %rd4;
	cvta.global.u64 	%rd6, %rd5;
	cvta.to.global.u64 	%rd7, %rd3;
	cvta.global.u64 	%rd8, %rd7;
	st.u64 	[%SP+0], %rd1;
	st.u64 	[%SP+8], %rd2;
	st.u64 	[%SP+16], %rd8;
	st.u64 	[%SP+24], %rd6;
	mov.u64 	%rd9, 0;
	st.u64 	[%SP+56], %rd9;
	st.u64 	[%SP+64], %rd9;
	st.u64 	[%SP+72], %rd9;
	bra.uni 	$L__BB24_1;
$L__BB24_1:
	{ // callseq 55, 0
	.reg .b32 temp_param_reg;
	.param .b32 retval0;
	call.uni (retval0), 
	_ZL21chpl_gpu_getBlockIdxXv, 
	(
	);
	ld.param.b32 	%r1, [retval0+0];
	} // callseq 55
	cvt.s64.s32 	%rd10, %r1;
	st.u64 	[%SP+32], %rd10;
	{ // callseq 56, 0
	.reg .b32 temp_param_reg;
	.param .b32 retval0;
	call.uni (retval0), 
	_ZL21chpl_gpu_getBlockDimXv, 
	(
	);
	ld.param.b32 	%r3, [retval0+0];
	} // callseq 56
	st.u32 	[%SP+40], %r3;
	{ // callseq 57, 0
	.reg .b32 temp_param_reg;
	.param .b32 retval0;
	call.uni (retval0), 
	_ZL22chpl_gpu_getThreadIdxXv, 
	(
	);
	ld.param.b32 	%r5, [retval0+0];
	} // callseq 57
	st.u32 	[%SP+44], %r5;
	ld.u64 	%rd11, [%SP+32];
	ld.s32 	%rd12, [%SP+40];
	mul.lo.s64 	%rd13, %rd11, %rd12;
	ld.s32 	%rd14, [%SP+44];
	add.s64 	%rd15, %rd13, %rd14;
	ld.u64 	%rd16, [%SP+0];
	add.s64 	%rd17, %rd15, %rd16;
	st.u64 	[%SP+48], %rd17;
	bra.uni 	$L__BB24_2;
$L__BB24_2:
	ld.u64 	%rd18, [%SP+48];
	ld.u64 	%rd19, [%SP+8];
	setp.le.s64 	%p1, %rd18, %rd19;
	@%p1 bra 	$L__BB24_5;
	bra.uni 	$L__BB24_3;
$L__BB24_3:
	bra.uni 	$L__BB24_4;
$L__BB24_4:
	bra.uni 	$L__BB24_6;
$L__BB24_5:
	ld.u64 	%rd20, [%SP+48];
	ld.u64 	%rd21, [%SP+16];
	shl.b64 	%rd22, %rd20, 3;
	add.s64 	%rd23, %rd21, %rd22;
	st.u64 	[%SP+64], %rd23;
	ld.u64 	%rd24, [%SP+64];
	st.u64 	[%SP+56], %rd24;
	ld.u64 	%rd25, [%SP+48];
	ld.u64 	%rd26, [%SP+24];
	shl.b64 	%rd27, %rd25, 3;
	add.s64 	%rd28, %rd26, %rd27;
	st.u64 	[%SP+72], %rd28;
	ld.u64 	%rd29, [%SP+56];
	ld.u64 	%rd30, [%SP+72];
	ld.u64 	%rd31, [%rd30];
	st.u64 	[%rd29], %rd31;
	bra.uni 	$L__BB24_6;
$L__BB24_6:
	ret;

}
	// .globl	chpl_gpu_kernel_DefaultRectangular_line_1550_
.visible .entry chpl_gpu_kernel_DefaultRectangular_line_1550_(
	.param .u64 chpl_gpu_kernel_DefaultRectangular_line_1550__param_0,
	.param .u64 chpl_gpu_kernel_DefaultRectangular_line_1550__param_1,
	.param .u64 chpl_gpu_kernel_DefaultRectangular_line_1550__param_2,
	.param .u64 chpl_gpu_kernel_DefaultRectangular_line_1550__param_3
)
{
	.local .align 8 .b8 	__local_depot25[112];
	.reg .b64 	%SP;
	.reg .b64 	%SPL;
	.reg .pred 	%p<3>;
	.reg .b16 	%rs<2>;
	.reg .b32 	%r<18>;
	.reg .b64 	%rd<36>;

	mov.u64 	%SPL, __local_depot25;
	cvta.local.u64 	%SP, %SPL;
	ld.param.u64 	%rd4, [chpl_gpu_kernel_DefaultRectangular_line_1550__param_3];
	ld.param.u64 	%rd3, [chpl_gpu_kernel_DefaultRectangular_line_1550__param_2];
	ld.param.u64 	%rd2, [chpl_gpu_kernel_DefaultRectangular_line_1550__param_1];
	ld.param.u64 	%rd1, [chpl_gpu_kernel_DefaultRectangular_line_1550__param_0];
	cvta.to.global.u64 	%rd5, %rd4;
	cvta.global.u64 	%rd6, %rd5;
	cvta.to.global.u64 	%rd7, %rd3;
	cvta.global.u64 	%rd8, %rd7;
	st.u64 	[%SP+0], %rd1;
	st.u64 	[%SP+8], %rd2;
	st.u64 	[%SP+16], %rd8;
	st.u64 	[%SP+24], %rd6;
	mov.u64 	%rd9, 0;
	st.u64 	[%SP+72], %rd9;
	add.u64 	%rd10, %SP, 80;
	or.b64  	%rd11, %rd10, 4;
	mov.u32 	%r1, 0;
	st.u32 	[%rd11], %r1;
	st.u64 	[%SP+88], %rd9;
	st.u32 	[%SP+80], %r1;
	bra.uni 	$L__BB25_1;
$L__BB25_1:
	{ // callseq 58, 0
	.reg .b32 temp_param_reg;
	.param .b32 retval0;
	call.uni (retval0), 
	_ZL21chpl_gpu_getBlockIdxXv, 
	(
	);
	ld.param.b32 	%r2, [retval0+0];
	} // callseq 58
	cvt.s64.s32 	%rd12, %r2;
	st.u64 	[%SP+32], %rd12;
	{ // callseq 59, 0
	.reg .b32 temp_param_reg;
	.param .b32 retval0;
	call.uni (retval0), 
	_ZL21chpl_gpu_getBlockDimXv, 
	(
	);
	ld.param.b32 	%r4, [retval0+0];
	} // callseq 59
	st.u32 	[%SP+40], %r4;
	{ // callseq 60, 0
	.reg .b32 temp_param_reg;
	.param .b32 retval0;
	call.uni (retval0), 
	_ZL22chpl_gpu_getThreadIdxXv, 
	(
	);
	ld.param.b32 	%r6, [retval0+0];
	} // callseq 60
	st.u32 	[%SP+44], %r6;
	ld.u64 	%rd13, [%SP+32];
	ld.s32 	%rd14, [%SP+40];
	mul.lo.s64 	%rd15, %rd13, %rd14;
	ld.s32 	%rd16, [%SP+44];
	add.s64 	%rd17, %rd15, %rd16;
	ld.u64 	%rd18, [%SP+0];
	add.s64 	%rd19, %rd17, %rd18;
	st.u64 	[%SP+48], %rd19;
	bra.uni 	$L__BB25_2;
$L__BB25_2:
	ld.u64 	%rd20, [%SP+48];
	ld.u64 	%rd21, [%SP+8];
	setp.le.s64 	%p1, %rd20, %rd21;
	@%p1 bra 	$L__BB25_5;
	bra.uni 	$L__BB25_3;
$L__BB25_3:
	bra.uni 	$L__BB25_4;
$L__BB25_4:
	bra.uni 	$L__BB25_10;
$L__BB25_5:
	ld.u64 	%rd22, [%SP+48];
	st.u64 	[%SP+56], %rd22;
	ld.u64 	%rd23, [%SP+16];
	add.u64 	%rd24, %SP, 56;
	{ // callseq 61, 0
	.reg .b32 temp_param_reg;
	.param .b64 param0;
	st.param.b64 	[param0+0], %rd23;
	.param .b64 param1;
	st.param.b64 	[param1+0], %rd24;
	.param .b32 retval0;
	call.uni (retval0), 
	_local_contains_chpl, 
	(
	param0, 
	param1
	);
	ld.param.b32 	%r8, [retval0+0];
	} // callseq 61
	st.u8 	[%SP+64], %r8;
	bra.uni 	$L__BB25_6;
$L__BB25_6:
	ld.u8 	%rs1, [%SP+64];
	setp.ne.s16 	%p2, %rs1, 0;
	@%p2 bra 	$L__BB25_9;
	bra.uni 	$L__BB25_7;
$L__BB25_7:
	bra.uni 	$L__BB25_8;
$L__BB25_8:
	ld.u64 	%rd25, [%SP+48];
	ld.u64 	%rd26, [%SP+24];
	shl.b64 	%rd27, %rd25, 4;
	add.s64 	%rd28, %rd26, %rd27;
	st.u64 	[%SP+72], %rd28;
	{ // callseq 62, 0
	.reg .b32 temp_param_reg;
	.param .align 16 .b8 retval0[8];
	call.uni (retval0), 
	_ZL20chpl_gen_getLocaleIDv, 
	(
	);
	ld.param.v2.b32 	{%r10, %r11}, [retval0+0];
	} // callseq 62
	ld.u64 	%rd29, [%SP+72];
	st.u64 	[%SP+104], %rd29;
	add.u64 	%rd30, %SP, 96;
	or.b64  	%rd31, %rd30, 4;
	st.u32 	[%rd31], %r11;
	st.u32 	[%SP+96], %r10;
	ld.u32 	%r14, [%rd31];
	ld.u32 	%r15, [%SP+96];
	ld.u64 	%rd32, [%SP+104];
	add.u64 	%rd33, %SP, 80;
	or.b64  	%rd34, %rd33, 4;
	st.u32 	[%rd34], %r14;
	st.u64 	[%SP+88], %rd32;
	st.u32 	[%SP+80], %r15;
	ld.u32 	%r16, [%rd34];
	ld.u64 	%rd35, [%SP+88];
	ld.u32 	%r17, [%SP+80];
	{ // callseq 63, 0
	.reg .b32 temp_param_reg;
	.param .align 8 .b8 param0[16];
	st.param.v2.b32 	[param0+0], {%r17, %r16};
	st.param.b64 	[param0+8], %rd35;
	call.uni 
	_local_deinit_chpl, 
	(
	param0
	);
	} // callseq 63
	bra.uni 	$L__BB25_9;
$L__BB25_9:
	bra.uni 	$L__BB25_10;
$L__BB25_10:
	ret;

}
.func  (.param .b32 func_retval0) _local_chpl_nodeFromLocaleID_chpl(
	.param .align 16 .b8 _local_chpl_nodeFromLocaleID_chpl_param_0[8],
	.param .b64 _local_chpl_nodeFromLocaleID_chpl_param_1,
	.param .b32 _local_chpl_nodeFromLocaleID_chpl_param_2
)
{
	.local .align 8 .b8 	__local_depot26[32];
	.reg .b64 	%SP;
	.reg .b64 	%SPL;
	.reg .b32 	%r<11>;
	.reg .b64 	%rd<8>;

	mov.u64 	%SPL, __local_depot26;
	cvta.local.u64 	%SP, %SPL;
	ld.param.u32 	%r2, [_local_chpl_nodeFromLocaleID_chpl_param_0+4];
	ld.param.u32 	%r1, [_local_chpl_nodeFromLocaleID_chpl_param_0];
	ld.param.u32 	%r3, [_local_chpl_nodeFromLocaleID_chpl_param_2];
	ld.param.u64 	%rd1, [_local_chpl_nodeFromLocaleID_chpl_param_1];
	add.u64 	%rd2, %SP, 0;
	or.b64  	%rd3, %rd2, 4;
	st.u32 	[%rd3], %r2;
	st.u32 	[%SP+0], %r1;
	st.u64 	[%SP+8], %rd1;
	st.u32 	[%SP+16], %r3;
	bra.uni 	$L__BB26_1;
$L__BB26_1:
	add.u64 	%rd4, %SP, 0;
	or.b64  	%rd5, %rd4, 4;
	ld.u32 	%r4, [%rd5];
	ld.u32 	%r5, [%SP+0];
	add.u64 	%rd6, %SP, 24;
	or.b64  	%rd7, %rd6, 4;
	st.u32 	[%rd7], %r4;
	st.u32 	[%SP+24], %r5;
	ld.u32 	%r6, [%rd7];
	ld.u32 	%r7, [%SP+24];
	{ // callseq 64, 0
	.reg .b32 temp_param_reg;
	.param .align 16 .b8 param0[8];
	st.param.v2.b32 	[param0+0], {%r7, %r6};
	.param .b32 retval0;
	call.uni (retval0), 
	_ZL24chpl_rt_nodeFromLocaleID15chpl_localeID_t, 
	(
	param0
	);
	ld.param.b32 	%r8, [retval0+0];
	} // callseq 64
	st.u32 	[%SP+20], %r8;
	ld.u32 	%r10, [%SP+20];
	st.param.b32 	[func_retval0+0], %r10;
	ret;

}
.func  (.param .b32 func_retval0) chpl_nodeFromLocaleID(
	.param .align 16 .b8 chpl_nodeFromLocaleID_param_0[8],
	.param .b64 chpl_nodeFromLocaleID_param_1,
	.param .b32 chpl_nodeFromLocaleID_param_2
)
{
	.local .align 8 .b8 	__local_depot27[32];
	.reg .b64 	%SP;
	.reg .b64 	%SPL;
	.reg .b32 	%r<11>;
	.reg .b64 	%rd<8>;

	mov.u64 	%SPL, __local_depot27;
	cvta.local.u64 	%SP, %SPL;
	ld.param.u32 	%r2, [chpl_nodeFromLocaleID_param_0+4];
	ld.param.u32 	%r1, [chpl_nodeFromLocaleID_param_0];
	ld.param.u32 	%r3, [chpl_nodeFromLocaleID_param_2];
	ld.param.u64 	%rd1, [chpl_nodeFromLocaleID_param_1];
	add.u64 	%rd2, %SP, 0;
	or.b64  	%rd3, %rd2, 4;
	st.u32 	[%rd3], %r2;
	st.u32 	[%SP+0], %r1;
	st.u64 	[%SP+8], %rd1;
	st.u32 	[%SP+16], %r3;
	bra.uni 	$L__BB27_1;
$L__BB27_1:
	add.u64 	%rd4, %SP, 0;
	or.b64  	%rd5, %rd4, 4;
	ld.u32 	%r4, [%rd5];
	ld.u32 	%r5, [%SP+0];
	add.u64 	%rd6, %SP, 24;
	or.b64  	%rd7, %rd6, 4;
	st.u32 	[%rd7], %r4;
	st.u32 	[%SP+24], %r5;
	ld.u32 	%r6, [%rd7];
	ld.u32 	%r7, [%SP+24];
	{ // callseq 65, 0
	.reg .b32 temp_param_reg;
	.param .align 16 .b8 param0[8];
	st.param.v2.b32 	[param0+0], {%r7, %r6};
	.param .b32 retval0;
	call.uni (retval0), 
	_ZL24chpl_rt_nodeFromLocaleID15chpl_localeID_t, 
	(
	param0
	);
	ld.param.b32 	%r8, [retval0+0];
	} // callseq 65
	st.u32 	[%SP+20], %r8;
	ld.u32 	%r10, [%SP+20];
	st.param.b32 	[func_retval0+0], %r10;
	ret;

}
.func  (.param .b32 func_retval0) _local_chpl_sublocFromLocaleID_chpl(
	.param .align 16 .b8 _local_chpl_sublocFromLocaleID_chpl_param_0[8],
	.param .b64 _local_chpl_sublocFromLocaleID_chpl_param_1,
	.param .b32 _local_chpl_sublocFromLocaleID_chpl_param_2
)
{
	.local .align 8 .b8 	__local_depot28[32];
	.reg .b64 	%SP;
	.reg .b64 	%SPL;
	.reg .b32 	%r<11>;
	.reg .b64 	%rd<8>;

	mov.u64 	%SPL, __local_depot28;
	cvta.local.u64 	%SP, %SPL;
	ld.param.u32 	%r2, [_local_chpl_sublocFromLocaleID_chpl_param_0+4];
	ld.param.u32 	%r1, [_local_chpl_sublocFromLocaleID_chpl_param_0];
	ld.param.u32 	%r3, [_local_chpl_sublocFromLocaleID_chpl_param_2];
	ld.param.u64 	%rd1, [_local_chpl_sublocFromLocaleID_chpl_param_1];
	add.u64 	%rd2, %SP, 0;
	or.b64  	%rd3, %rd2, 4;
	st.u32 	[%rd3], %r2;
	st.u32 	[%SP+0], %r1;
	st.u64 	[%SP+8], %rd1;
	st.u32 	[%SP+16], %r3;
	bra.uni 	$L__BB28_1;
$L__BB28_1:
	add.u64 	%rd4, %SP, 0;
	or.b64  	%rd5, %rd4, 4;
	ld.u32 	%r4, [%rd5];
	ld.u32 	%r5, [%SP+0];
	add.u64 	%rd6, %SP, 24;
	or.b64  	%rd7, %rd6, 4;
	st.u32 	[%rd7], %r4;
	st.u32 	[%SP+24], %r5;
	ld.u32 	%r6, [%rd7];
	ld.u32 	%r7, [%SP+24];
	{ // callseq 66, 0
	.reg .b32 temp_param_reg;
	.param .align 16 .b8 param0[8];
	st.param.v2.b32 	[param0+0], {%r7, %r6};
	.param .b32 retval0;
	call.uni (retval0), 
	_ZL26chpl_rt_sublocFromLocaleID15chpl_localeID_t, 
	(
	param0
	);
	ld.param.b32 	%r8, [retval0+0];
	} // callseq 66
	st.u32 	[%SP+20], %r8;
	ld.u32 	%r10, [%SP+20];
	st.param.b32 	[func_retval0+0], %r10;
	ret;

}
.func  (.param .b32 func_retval0) chpl_sublocFromLocaleID(
	.param .align 16 .b8 chpl_sublocFromLocaleID_param_0[8],
	.param .b64 chpl_sublocFromLocaleID_param_1,
	.param .b32 chpl_sublocFromLocaleID_param_2
)
{
	.local .align 8 .b8 	__local_depot29[32];
	.reg .b64 	%SP;
	.reg .b64 	%SPL;
	.reg .b32 	%r<11>;
	.reg .b64 	%rd<8>;

	mov.u64 	%SPL, __local_depot29;
	cvta.local.u64 	%SP, %SPL;
	ld.param.u32 	%r2, [chpl_sublocFromLocaleID_param_0+4];
	ld.param.u32 	%r1, [chpl_sublocFromLocaleID_param_0];
	ld.param.u32 	%r3, [chpl_sublocFromLocaleID_param_2];
	ld.param.u64 	%rd1, [chpl_sublocFromLocaleID_param_1];
	add.u64 	%rd2, %SP, 0;
	or.b64  	%rd3, %rd2, 4;
	st.u32 	[%rd3], %r2;
	st.u32 	[%SP+0], %r1;
	st.u64 	[%SP+8], %rd1;
	st.u32 	[%SP+16], %r3;
	bra.uni 	$L__BB29_1;
$L__BB29_1:
	add.u64 	%rd4, %SP, 0;
	or.b64  	%rd5, %rd4, 4;
	ld.u32 	%r4, [%rd5];
	ld.u32 	%r5, [%SP+0];
	add.u64 	%rd6, %SP, 24;
	or.b64  	%rd7, %rd6, 4;
	st.u32 	[%rd7], %r4;
	st.u32 	[%SP+24], %r5;
	ld.u32 	%r6, [%rd7];
	ld.u32 	%r7, [%SP+24];
	{ // callseq 67, 0
	.reg .b32 temp_param_reg;
	.param .align 16 .b8 param0[8];
	st.param.v2.b32 	[param0+0], {%r7, %r6};
	.param .b32 retval0;
	call.uni (retval0), 
	_ZL26chpl_rt_sublocFromLocaleID15chpl_localeID_t, 
	(
	param0
	);
	ld.param.b32 	%r8, [retval0+0];
	} // callseq 67
	st.u32 	[%SP+20], %r8;
	ld.u32 	%r10, [%SP+20];
	st.param.b32 	[func_retval0+0], %r10;
	ret;

}
	// .globl	chpl_gpu_kernel_test_line_43_
.visible .entry chpl_gpu_kernel_test_line_43_(
	.param .u64 chpl_gpu_kernel_test_line_43__param_0,
	.param .u64 chpl_gpu_kernel_test_line_43__param_1,
	.param .u64 chpl_gpu_kernel_test_line_43__param_2,
	.param .u64 chpl_gpu_kernel_test_line_43__param_3,
	.param .u64 chpl_gpu_kernel_test_line_43__param_4,
	.param .u64 chpl_gpu_kernel_test_line_43__param_5,
	.param .u64 chpl_gpu_kernel_test_line_43__param_6
)
{
	.local .align 8 .b8 	__local_depot30[240];
	.reg .b64 	%SP;
	.reg .b64 	%SPL;
	.reg .pred 	%p<2>;
	.reg .b32 	%r<7>;
	.reg .b64 	%rd<76>;
	.reg .f64 	%fd<2>;

	mov.u64 	%SPL, __local_depot30;
	cvta.local.u64 	%SP, %SPL;
	ld.param.u64 	%rd7, [chpl_gpu_kernel_test_line_43__param_6];
	ld.param.u64 	%rd6, [chpl_gpu_kernel_test_line_43__param_5];
	ld.param.u64 	%rd5, [chpl_gpu_kernel_test_line_43__param_4];
	ld.param.u64 	%rd4, [chpl_gpu_kernel_test_line_43__param_3];
	ld.param.u64 	%rd3, [chpl_gpu_kernel_test_line_43__param_2];
	ld.param.u64 	%rd2, [chpl_gpu_kernel_test_line_43__param_1];
	ld.param.u64 	%rd1, [chpl_gpu_kernel_test_line_43__param_0];
	cvta.to.global.u64 	%rd8, %rd7;
	cvta.global.u64 	%rd9, %rd8;
	cvta.to.global.u64 	%rd10, %rd6;
	cvta.global.u64 	%rd11, %rd10;
	cvta.to.global.u64 	%rd12, %rd5;
	cvta.global.u64 	%rd13, %rd12;
	cvta.to.global.u64 	%rd14, %rd4;
	cvta.global.u64 	%rd15, %rd14;
	st.u64 	[%SP+0], %rd1;
	st.u64 	[%SP+8], %rd2;
	st.u64 	[%SP+16], %rd3;
	st.u64 	[%SP+24], %rd15;
	st.u64 	[%SP+32], %rd13;
	st.u64 	[%SP+40], %rd11;
	st.u64 	[%SP+48], %rd9;
	mov.u64 	%rd16, 0;
	st.u64 	[%SP+136], %rd16;
	st.u64 	[%SP+144], %rd16;
	st.u64 	[%SP+152], %rd16;
	st.u64 	[%SP+160], %rd16;
	st.u64 	[%SP+208], %rd16;
	st.u64 	[%SP+216], %rd16;
	st.u64 	[%SP+224], %rd16;
	st.u64 	[%SP+232], %rd16;
	bra.uni 	$L__BB30_1;
$L__BB30_1:
	{ // callseq 68, 0
	.reg .b32 temp_param_reg;
	.param .b32 retval0;
	call.uni (retval0), 
	_ZL21chpl_gpu_getBlockIdxXv, 
	(
	);
	ld.param.b32 	%r1, [retval0+0];
	} // callseq 68
	cvt.s64.s32 	%rd17, %r1;
	st.u64 	[%SP+56], %rd17;
	{ // callseq 69, 0
	.reg .b32 temp_param_reg;
	.param .b32 retval0;
	call.uni (retval0), 
	_ZL21chpl_gpu_getBlockDimXv, 
	(
	);
	ld.param.b32 	%r3, [retval0+0];
	} // callseq 69
	st.u32 	[%SP+64], %r3;
	{ // callseq 70, 0
	.reg .b32 temp_param_reg;
	.param .b32 retval0;
	call.uni (retval0), 
	_ZL22chpl_gpu_getThreadIdxXv, 
	(
	);
	ld.param.b32 	%r5, [retval0+0];
	} // callseq 70
	st.u32 	[%SP+68], %r5;
	ld.u64 	%rd18, [%SP+56];
	ld.s32 	%rd19, [%SP+64];
	mul.lo.s64 	%rd20, %rd18, %rd19;
	ld.s32 	%rd21, [%SP+68];
	add.s64 	%rd22, %rd20, %rd21;
	ld.u64 	%rd23, [%SP+0];
	add.s64 	%rd24, %rd22, %rd23;
	st.u64 	[%SP+72], %rd24;
	bra.uni 	$L__BB30_2;
$L__BB30_2:
	ld.u64 	%rd25, [%SP+72];
	ld.u64 	%rd26, [%SP+8];
	setp.le.s64 	%p1, %rd25, %rd26;
	@%p1 bra 	$L__BB30_5;
	bra.uni 	$L__BB30_3;
$L__BB30_3:
	bra.uni 	$L__BB30_4;
$L__BB30_4:
	bra.uni 	$L__BB30_6;
$L__BB30_5:
	ld.u64 	%rd27, [%SP+16];
	st.u64 	[%SP+80], %rd27;
	ld.u64 	%rd28, [%SP+72];
	st.u64 	[%SP+88], %rd28;
	ld.u64 	%rd29, [%SP+80];
	st.u64 	[%SP+96], %rd29;
	ld.u64 	%rd30, [%SP+88];
	st.u64 	[%SP+104], %rd30;
	ld.u64 	%rd31, [%SP+104];
	st.u64 	[%SP+112], %rd31;
	mov.u64 	%rd32, 0;
	st.u64 	[%SP+128], %rd32;
	ld.u64 	%rd33, [%SP+24];
	add.s64 	%rd34, %rd33, 96;
	st.u64 	[%SP+136], %rd34;
	add.u64 	%rd35, %SP, 128;
	st.u64 	[%SP+144], %rd35;
	ld.u64 	%rd36, [%SP+136];
	ld.u64 	%rd37, [%SP+96];
	ld.u64 	%rd38, [%rd36];
	mul.lo.s64 	%rd39, %rd37, %rd38;
	ld.u64 	%rd40, [%SP+144];
	ld.u64 	%rd41, [%rd40];
	add.s64 	%rd42, %rd41, %rd39;
	st.u64 	[%rd40], %rd42;
	st.u64 	[%SP+152], %rd35;
	ld.u64 	%rd43, [%SP+152];
	ld.u64 	%rd44, [%SP+112];
	ld.u64 	%rd45, [%rd43];
	add.s64 	%rd46, %rd45, %rd44;
	st.u64 	[%rd43], %rd46;
	ld.u64 	%rd47, [%SP+128];
	st.u64 	[%SP+120], %rd47;
	ld.u64 	%rd48, [%SP+120];
	ld.u64 	%rd49, [%SP+32];
	shl.b64 	%rd50, %rd48, 3;
	add.s64 	%rd51, %rd49, %rd50;
	st.u64 	[%SP+160], %rd51;
	ld.u64 	%rd52, [%SP+80];
	st.u64 	[%SP+168], %rd52;
	ld.u64 	%rd53, [%SP+88];
	st.u64 	[%SP+176], %rd53;
	ld.u64 	%rd54, [%SP+176];
	st.u64 	[%SP+184], %rd54;
	st.u64 	[%SP+200], %rd32;
	ld.u64 	%rd55, [%SP+40];
	add.s64 	%rd56, %rd55, 96;
	st.u64 	[%SP+208], %rd56;
	add.u64 	%rd57, %SP, 200;
	st.u64 	[%SP+216], %rd57;
	ld.u64 	%rd58, [%SP+208];
	ld.u64 	%rd59, [%SP+168];
	ld.u64 	%rd60, [%rd58];
	mul.lo.s64 	%rd61, %rd59, %rd60;
	ld.u64 	%rd62, [%SP+216];
	ld.u64 	%rd63, [%rd62];
	add.s64 	%rd64, %rd63, %rd61;
	st.u64 	[%rd62], %rd64;
	st.u64 	[%SP+224], %rd57;
	ld.u64 	%rd65, [%SP+224];
	ld.u64 	%rd66, [%SP+184];
	ld.u64 	%rd67, [%rd65];
	add.s64 	%rd68, %rd67, %rd66;
	st.u64 	[%rd65], %rd68;
	ld.u64 	%rd69, [%SP+200];
	st.u64 	[%SP+192], %rd69;
	ld.u64 	%rd70, [%SP+192];
	ld.u64 	%rd71, [%SP+48];
	shl.b64 	%rd72, %rd70, 3;
	add.s64 	%rd73, %rd71, %rd72;
	st.u64 	[%SP+232], %rd73;
	ld.u64 	%rd74, [%SP+160];
	ld.u64 	%rd75, [%SP+232];
	ld.f64 	%fd1, [%rd75];
	st.f64 	[%rd74], %fd1;
	bra.uni 	$L__BB30_6;
$L__BB30_6:
	ret;

}
	// .globl	chpl_gpu_kernel_test_line_43_2
.visible .entry chpl_gpu_kernel_test_line_43_2(
	.param .u64 chpl_gpu_kernel_test_line_43_2_param_0,
	.param .u64 chpl_gpu_kernel_test_line_43_2_param_1,
	.param .u64 chpl_gpu_kernel_test_line_43_2_param_2,
	.param .u64 chpl_gpu_kernel_test_line_43_2_param_3,
	.param .u64 chpl_gpu_kernel_test_line_43_2_param_4,
	.param .u64 chpl_gpu_kernel_test_line_43_2_param_5
)
{
	.local .align 8 .b8 	__local_depot31[312];
	.reg .b64 	%SP;
	.reg .b64 	%SPL;
	.reg .pred 	%p<4>;
	.reg .b32 	%r<12>;
	.reg .b64 	%rd<98>;
	.reg .f64 	%fd<2>;

	mov.u64 	%SPL, __local_depot31;
	cvta.local.u64 	%SP, %SPL;
	ld.param.u64 	%rd6, [chpl_gpu_kernel_test_line_43_2_param_5];
	ld.param.u64 	%rd5, [chpl_gpu_kernel_test_line_43_2_param_4];
	ld.param.u64 	%rd4, [chpl_gpu_kernel_test_line_43_2_param_3];
	ld.param.u64 	%rd3, [chpl_gpu_kernel_test_line_43_2_param_2];
	ld.param.u64 	%rd2, [chpl_gpu_kernel_test_line_43_2_param_1];
	ld.param.u64 	%rd1, [chpl_gpu_kernel_test_line_43_2_param_0];
	cvta.to.global.u64 	%rd7, %rd4;
	cvta.global.u64 	%rd8, %rd7;
	cvta.to.global.u64 	%rd9, %rd3;
	cvta.global.u64 	%rd10, %rd9;
	st.u64 	[%SP+0], %rd1;
	st.u64 	[%SP+8], %rd2;
	st.u64 	[%SP+16], %rd10;
	st.u64 	[%SP+24], %rd8;
	st.u64 	[%SP+32], %rd5;
	st.u64 	[%SP+40], %rd6;
	mov.u64 	%rd11, 0;
	st.u64 	[%SP+104], %rd11;
	st.u64 	[%SP+152], %rd11;
	st.u64 	[%SP+160], %rd11;
	st.u64 	[%SP+168], %rd11;
	st.u64 	[%SP+176], %rd11;
	add.u64 	%rd12, %SP, 184;
	or.b64  	%rd13, %rd12, 4;
	mov.u32 	%r1, 0;
	st.u32 	[%rd13], %r1;
	st.u64 	[%SP+192], %rd11;
	st.u32 	[%SP+184], %r1;
	st.u64 	[%SP+200], %rd11;
	st.u64 	[%SP+208], %rd11;
	st.u64 	[%SP+256], %rd11;
	st.u64 	[%SP+264], %rd11;
	st.u64 	[%SP+272], %rd11;
	st.u64 	[%SP+280], %rd11;
	add.u64 	%rd14, %SP, 288;
	or.b64  	%rd15, %rd14, 4;
	st.u32 	[%rd15], %r1;
	st.u64 	[%SP+296], %rd11;
	st.u32 	[%SP+288], %r1;
	st.u64 	[%SP+304], %rd11;
	bra.uni 	$L__BB31_1;
$L__BB31_1:
	{ // callseq 71, 0
	.reg .b32 temp_param_reg;
	.param .b32 retval0;
	call.uni (retval0), 
	_ZL21chpl_gpu_getBlockIdxXv, 
	(
	);
	ld.param.b32 	%r2, [retval0+0];
	} // callseq 71
	cvt.s64.s32 	%rd16, %r2;
	st.u64 	[%SP+48], %rd16;
	{ // callseq 72, 0
	.reg .b32 temp_param_reg;
	.param .b32 retval0;
	call.uni (retval0), 
	_ZL21chpl_gpu_getBlockDimXv, 
	(
	);
	ld.param.b32 	%r4, [retval0+0];
	} // callseq 72
	st.u32 	[%SP+56], %r4;
	{ // callseq 73, 0
	.reg .b32 temp_param_reg;
	.param .b32 retval0;
	call.uni (retval0), 
	_ZL22chpl_gpu_getThreadIdxXv, 
	(
	);
	ld.param.b32 	%r6, [retval0+0];
	} // callseq 73
	st.u32 	[%SP+60], %r6;
	ld.u64 	%rd17, [%SP+48];
	ld.s32 	%rd18, [%SP+56];
	mul.lo.s64 	%rd19, %rd17, %rd18;
	ld.s32 	%rd20, [%SP+60];
	add.s64 	%rd21, %rd19, %rd20;
	ld.u64 	%rd22, [%SP+0];
	add.s64 	%rd23, %rd21, %rd22;
	st.u64 	[%SP+64], %rd23;
	bra.uni 	$L__BB31_2;
$L__BB31_2:
	ld.u64 	%rd24, [%SP+64];
	ld.u64 	%rd25, [%SP+8];
	setp.le.s64 	%p1, %rd24, %rd25;
	@%p1 bra 	$L__BB31_5;
	bra.uni 	$L__BB31_3;
$L__BB31_3:
	bra.uni 	$L__BB31_4;
$L__BB31_4:
	bra.uni 	$L__BB31_9;
$L__BB31_5:
	ld.u64 	%rd26, [%SP+64];
	st.u64 	[%SP+72], %rd26;
	mov.u64 	%rd27, 0;
	st.u64 	[%SP+80], %rd27;
	bra.uni 	$L__BB31_6;
$L__BB31_6:
	ld.u64 	%rd28, [%SP+32];
	st.u64 	[%SP+80], %rd28;
	ld.u64 	%rd29, [%SP+80];
	ld.u64 	%rd30, [%SP+40];
	setp.gt.s64 	%p2, %rd29, %rd30;
	@%p2 bra 	$L__BB31_8;
	bra.uni 	$L__BB31_7;
$L__BB31_7:
	ld.u64 	%rd31, [%SP+72];
	st.u64 	[%SP+88], %rd31;
	ld.u64 	%rd32, [%SP+80];
	st.u64 	[%SP+96], %rd32;
	ld.u64 	%rd33, [%SP+16];
	ld.u64 	%rd34, [%rd33+8];
	st.u64 	[%SP+104], %rd34;
	ld.u64 	%rd35, [%SP+88];
	st.u64 	[%SP+112], %rd35;
	ld.u64 	%rd36, [%SP+96];
	st.u64 	[%SP+120], %rd36;
	ld.u64 	%rd37, [%SP+120];
	st.u64 	[%SP+128], %rd37;
	mov.u64 	%rd38, 0;
	st.u64 	[%SP+144], %rd38;
	ld.u64 	%rd39, [%SP+104];
	add.s64 	%rd40, %rd39, 96;
	st.u64 	[%SP+152], %rd40;
	add.u64 	%rd41, %SP, 144;
	st.u64 	[%SP+160], %rd41;
	ld.u64 	%rd42, [%SP+152];
	ld.u64 	%rd43, [%SP+112];
	ld.u64 	%rd44, [%rd42];
	mul.lo.s64 	%rd45, %rd43, %rd44;
	ld.u64 	%rd46, [%SP+160];
	ld.u64 	%rd47, [%rd46];
	add.s64 	%rd48, %rd47, %rd45;
	st.u64 	[%rd46], %rd48;
	st.u64 	[%SP+168], %rd41;
	ld.u64 	%rd49, [%SP+168];
	ld.u64 	%rd50, [%SP+128];
	ld.u64 	%rd51, [%rd49];
	add.s64 	%rd52, %rd51, %rd50;
	st.u64 	[%rd49], %rd52;
	ld.u64 	%rd53, [%SP+144];
	st.u64 	[%SP+136], %rd53;
	ld.u64 	%rd54, [%SP+104];
	ld.u32 	%r8, [%rd54+168];
	ld.u64 	%rd55, [%rd54+176];
	ld.u32 	%r9, [%rd54+172];
	add.u64 	%rd56, %SP, 184;
	or.b64  	%rd57, %rd56, 4;
	st.u32 	[%rd57], %r9;
	st.u64 	[%SP+192], %rd55;
	st.u32 	[%SP+184], %r8;
	ld.u64 	%rd58, [%SP+192];
	st.u64 	[%SP+176], %rd58;
	ld.u64 	%rd59, [%SP+136];
	ld.u64 	%rd60, [%SP+176];
	shl.b64 	%rd61, %rd59, 3;
	add.s64 	%rd62, %rd60, %rd61;
	st.u64 	[%SP+200], %rd62;
	ld.u64 	%rd63, [%SP+24];
	ld.u64 	%rd64, [%rd63+8];
	st.u64 	[%SP+208], %rd64;
	ld.u64 	%rd65, [%SP+88];
	st.u64 	[%SP+216], %rd65;
	ld.u64 	%rd66, [%SP+96];
	st.u64 	[%SP+224], %rd66;
	ld.u64 	%rd67, [%SP+224];
	st.u64 	[%SP+232], %rd67;
	st.u64 	[%SP+248], %rd38;
	ld.u64 	%rd68, [%SP+208];
	add.s64 	%rd69, %rd68, 96;
	st.u64 	[%SP+256], %rd69;
	add.u64 	%rd70, %SP, 248;
	st.u64 	[%SP+264], %rd70;
	ld.u64 	%rd71, [%SP+256];
	ld.u64 	%rd72, [%SP+216];
	ld.u64 	%rd73, [%rd71];
	mul.lo.s64 	%rd74, %rd72, %rd73;
	ld.u64 	%rd75, [%SP+264];
	ld.u64 	%rd76, [%rd75];
	add.s64 	%rd77, %rd76, %rd74;
	st.u64 	[%rd75], %rd77;
	st.u64 	[%SP+272], %rd70;
	ld.u64 	%rd78, [%SP+272];
	ld.u64 	%rd79, [%SP+232];
	ld.u64 	%rd80, [%rd78];
	add.s64 	%rd81, %rd80, %rd79;
	st.u64 	[%rd78], %rd81;
	ld.u64 	%rd82, [%SP+248];
	st.u64 	[%SP+240], %rd82;
	ld.u64 	%rd83, [%SP+208];
	ld.u32 	%r10, [%rd83+168];
	ld.u64 	%rd84, [%rd83+176];
	ld.u32 	%r11, [%rd83+172];
	add.u64 	%rd85, %SP, 288;
	or.b64  	%rd86, %rd85, 4;
	st.u32 	[%rd86], %r11;
	st.u64 	[%SP+296], %rd84;
	st.u32 	[%SP+288], %r10;
	ld.u64 	%rd87, [%SP+296];
	st.u64 	[%SP+280], %rd87;
	ld.u64 	%rd88, [%SP+240];
	ld.u64 	%rd89, [%SP+280];
	shl.b64 	%rd90, %rd88, 3;
	add.s64 	%rd91, %rd89, %rd90;
	st.u64 	[%SP+304], %rd91;
	ld.u64 	%rd92, [%SP+200];
	ld.u64 	%rd93, [%SP+304];
	ld.f64 	%fd1, [%rd93];
	st.f64 	[%rd92], %fd1;
	ld.u64 	%rd94, [%SP+80];
	add.s64 	%rd95, %rd94, 1;
	st.u64 	[%SP+80], %rd95;
	ld.u64 	%rd96, [%SP+80];
	ld.u64 	%rd97, [%SP+40];
	setp.le.s64 	%p3, %rd96, %rd97;
	@%p3 bra 	$L__BB31_7;
	bra.uni 	$L__BB31_8;
$L__BB31_8:
	bra.uni 	$L__BB31_9;
$L__BB31_9:
	ret;

}
.func  (.param .b32 func_retval0) _ZL21chpl_gpu_getBlockIdxXv()
{
	.reg .b32 	%r<2>;

	mov.u32 	%r1, %ctaid.x;
	st.param.b32 	[func_retval0+0], %r1;
	ret;

}
.func  (.param .b32 func_retval0) _ZL21chpl_gpu_getBlockDimXv()
{
	.reg .b32 	%r<2>;

	mov.u32 	%r1, %ntid.x;
	st.param.b32 	[func_retval0+0], %r1;
	ret;

}
.func  (.param .b32 func_retval0) _ZL22chpl_gpu_getThreadIdxXv()
{
	.reg .b32 	%r<2>;

	mov.u32 	%r1, %tid.x;
	st.param.b32 	[func_retval0+0], %r1;
	ret;

}
.func  (.param .align 16 .b8 func_retval0[8]) _ZL20chpl_gen_getLocaleIDv()
{
	.local .align 8 .b8 	__local_depot35[16];
	.reg .b64 	%SP;
	.reg .b64 	%SPL;
	.reg .b32 	%r<7>;
	.reg .b64 	%rd<6>;

	mov.u64 	%SPL, __local_depot35;
	cvta.local.u64 	%SP, %SPL;
	{ // callseq 74, 0
	.reg .b32 temp_param_reg;
	.param .b32 retval0;
	call.uni (retval0), 
	_ZL15get_chpl_nodeIDv, 
	(
	);
	ld.param.b32 	%r1, [retval0+0];
	} // callseq 74
	st.u32 	[%SP+8], %r1;
	add.u64 	%rd1, %SP, 8;
	or.b64  	%rd2, %rd1, 4;
	{ // callseq 75, 0
	.reg .b32 temp_param_reg;
	.param .b32 retval0;
	call.uni (retval0), 
	_ZL28chpl_task_getRequestedSublocv, 
	(
	);
	ld.param.b32 	%r3, [retval0+0];
	} // callseq 75
	st.u32 	[%rd2], %r3;
	ld.u64 	%rd3, [%SP+8];
	st.u64 	[%SP+0], %rd3;
	add.u64 	%rd4, %SP, 0;
	or.b64  	%rd5, %rd4, 4;
	ld.u32 	%r5, [%rd5];
	ld.u32 	%r6, [%SP+0];
	st.param.v2.b32 	[func_retval0+0], {%r6, %r5};
	ret;

}
.func  (.param .b32 func_retval0) _ZL24chpl_rt_nodeFromLocaleID15chpl_localeID_t(
	.param .align 16 .b8 _ZL24chpl_rt_nodeFromLocaleID15chpl_localeID_t_param_0[8]
)
{
	.reg .b32 	%r<2>;
	.reg .b64 	%rd<2>;

	mov.b64 	%rd1, _ZL24chpl_rt_nodeFromLocaleID15chpl_localeID_t_param_0;
	ld.param.u32 	%r1, [_ZL24chpl_rt_nodeFromLocaleID15chpl_localeID_t_param_0];
	st.param.b32 	[func_retval0+0], %r1;
	ret;

}
.func  (.param .b32 func_retval0) _ZL26chpl_rt_sublocFromLocaleID15chpl_localeID_t(
	.param .align 16 .b8 _ZL26chpl_rt_sublocFromLocaleID15chpl_localeID_t_param_0[8]
)
{
	.reg .b32 	%r<2>;
	.reg .b64 	%rd<2>;

	mov.b64 	%rd1, _ZL26chpl_rt_sublocFromLocaleID15chpl_localeID_t_param_0;
	ld.param.u32 	%r1, [_ZL26chpl_rt_sublocFromLocaleID15chpl_localeID_t_param_0+4];
	st.param.b32 	[func_retval0+0], %r1;
	ret;

}
.func  (.param .b32 func_retval0) _ZL15get_chpl_nodeIDv()
{
	.reg .b32 	%r<2>;
	.reg .b64 	%rd<3>;

	mov.u64 	%rd1, chpl_nodeID;
	cvta.global.u64 	%rd2, %rd1;
	ld.u32 	%r1, [%rd2];
	st.param.b32 	[func_retval0+0], %r1;
	ret;

}
.func  (.param .b32 func_retval0) _ZL28chpl_task_getRequestedSublocv()
{
	.reg .b32 	%r<2>;

	mov.u32 	%r1, 0;
	st.param.b32 	[func_retval0+0], %r1;
	ret;

}
